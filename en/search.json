[
  {
    "objectID": "dashboards_schema.html",
    "href": "dashboards_schema.html",
    "title": "Metadata Scheme",
    "section": "",
    "text": "ID\nProperty\nDefinition\nOcc\nValues\nExample\n\n\n\n\n1\nName\nName given to the dashboard by its authors, from (in descending priority): provided citation form, name given in associated publication, self-description on the website (header, ‘about’ page, self-referring term throughout the website), browser tab name; year is removed from dashboard name if there are versions for multiple years; instances of dashboard collections are named after the scheme ‘[Name of dashboard collection]: [Name of organization]’\n1\n\nFrench Open Science Monitor, CWTS Leiden Ranking, OpenAIRE Monitor Dashboard: Universität Göttingen\n\n\n2\nURL\nURL to homepage of the dashboard; if listed dashboard is only one of other dashboard-unrelated services on a website, URL of the specific webpage\n1\n\nhttps://open.coki.ac/\n\n\n3\nTime period\nTime period in years from the year of earliest data presented in the dashboard to the year of latest data; note: this is not the year of publication in the dashboard - ‘year of latest data’ earlier than 2024 does not necessarily mean the dashboard is inactive; the Leiden Ranking 2024 e.g. refers to data from 2019–2022\n1-n\n[year of common era]–[year of common era]\n2018–2024\n\n\n4\nOperator\nName of operator responsible for running the dashboard; if that operator does not have an associated ROR, but there is an organization containing the operator that has a ROR, this organization is listed after the original operator, separated by comma; multiple direct operators are separated by semicolon.\n1-n\n\nCentre for Science and Technology Studies (CWTS), Leiden University\n\n\n4.1\nROR\nROR of the organization(s) listed under 4 if available, N/A if unavailable\n1-n\nROR ID as an operable URL, N/A\nhttps://ror.org/027bh9e22\n\n\n4.2\nOperator type\nType of organization running the dashboard, distinguishing two major types of research-related organizations, Research Performing and Funding Organizations (‘RPO’ and ‘RFO’ respectively), with ‘other’ for everything else\n1-n\nResearch performing organization (RPO), Research funding organization (RFO), other\nRPO\n\n\n5.1\nScope\nScope of the coverage of dashboard: international if data for more than one country, national if data for one country, institutional if data on one or more organizations but not country-wide\n1\ninternational, national, research institution\ninternational\n\n\n5.2\nCountries\nCountry code of the organization(s) whose data are represented in the dashboard, represented with country code value ‘Europe’ if more than 1 country but all from EU + Switzerland OR Norway OR UK value ‘global’ if more than 1 country and more than 3 countries outside of ‘Europe’\n1-n\nControlled vocabulary: 3-letter ISO 3166-1 alpha-3 country code; additionally: ‘Europe’, ‘global’\nDEU\n\n\n6\nData type\nType of data that the dashboard shows ‘publications’ for data on textual publications such as e.g. journal articles ‘data’ for research data ‘software’ for research software ‘infrastructures’ for data on e.g. repositories ‘other’ for data that does not fall under any of the other categories\n1-n\npublications, data, software, infrustructures, other\npublications\n\n\n7\nDashboard license\nCopyright license of the software used to create the dashboard; if the dashboard provides a generic license for its website without specifically mentioning the software or its dataset, this license is instead entered here\n1-n\ncontrolled vocabulary: SPDX License List entries, N/A\nMIT, Apache-2.0\n\n\n8\nData license\nCopyright license under which the data of the dashboard is published\n1-n\ncontrolled vocabulary: SPDX License List entries, N/A\nCC-BY-4,0, CC0-1.0\n\n\n9\nData source\nAvailability of the data source the dashboard is based on: ‘open’ if data comes from an open source such as e.g. OpenAlex, ‘proprietary’ if not, both values if dashboard uses data sources of both types\n1-n\nopen, restricted, N/A\nopen\n\n\n10\nCollection\nNames the dashboard collection the dashboard is part of if applicable; ‘N/A’ otherwise\n1\nstring of the dashboard collection name, N/A\nOpenAIRE Monitor Dashboard, CHORUS dashboard\n\n\n11\nDocumentation\nFree text field in which relevant links and comments are gathered; these can include: links to the specific part of the website where the various licenses are mentioned, DOIs to accompanying publications about the dashboard and other comments\n1-n\nstring of comment, N/A\nData source: https://bibliotecnica.upc.edu/en/observatori#metodologia\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "OpenAlex.html",
    "href": "OpenAlex.html",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "",
    "text": "OpenAlex is a fully-open bibliographic database operated by the non-profit organization OurResearch. It launched in 2022 as a successor to the then discontinued Microsoft Academic Graph (Priem et al., 2022). OpenAlex data comprises information about various entities of the scholarly ecosystem such as research outputs (journal articles, books, datasets, etc.), authors, sources, etc. (OurResearch, n.d.).\nThe OpenAlex dataset is a useful tool to monitor open access activities on different levels of aggregation, as OpenAlex e.g. provides information on the open access status of a work or information on estimates for article processing charges (APCs) at the journal and work levels."
  },
  {
    "objectID": "OpenAlex.html#the-openalex-web-user-interface",
    "href": "OpenAlex.html#the-openalex-web-user-interface",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "The OpenAlex web user interface",
    "text": "The OpenAlex web user interface\nIn the web user interface you are able to query the database via a search bar, apply filters and export the results in csv, ris or txt format."
  },
  {
    "objectID": "OpenAlex.html#the-openalex-api",
    "href": "OpenAlex.html#the-openalex-api",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "The OpenAlex API",
    "text": "The OpenAlex API\nThe OpenAlex REST API allows programmatic access to and retrieval of OpenAlex data. The API has a limit of 100,000 calls per user per day1. Though no authentication is required it is advised to add your email address to all API requests in order to get into the polite pool2."
  },
  {
    "objectID": "OpenAlex.html#the-openalex-data-snapshot",
    "href": "OpenAlex.html#the-openalex-data-snapshot",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "The OpenAlex data snapshot",
    "text": "The OpenAlex data snapshot\nOpenAlex additionally offers a data snapshot with a copy of the complete database for download, which a user can then load into their own data warehouse or relational database. The snapshot gets updated monthly."
  },
  {
    "objectID": "OpenAlex.html#loading-packages",
    "href": "OpenAlex.html#loading-packages",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Loading packages",
    "text": "Loading packages\nWe will load the openalexR package (Aria et al., 2024) that allows us to query the OpenAlex API from within our notebook. We will also load the packages dplyr (Wickham et al., 2023), tidyr (Wickham et al., 2024), stringr (Wickham, 2025) and ggplot2 (Wickham, 2016) that provide a lot of additional functionalities for data wrangling and visualization and are part of the tidyverse package (Wickham et al., 2019).\n\n# Installation of packages if not already installed with\n# install.packages(c(\"openalexR\",\"dplyr\",\"tidyr\",\"stringr\",\"ggplot2\"))\nlibrary(openalexR)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "OpenAlex.html#loading-data",
    "href": "OpenAlex.html#loading-data",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Loading data",
    "text": "Loading data\nWe will use the oa_fetch function from the openalexR package to query the OpenAlex API and store the returned tibble (a data frame that works well with the tidyverse) in the object df.\n\ndf &lt;- oa_fetch(\n  entity = \"works\",\n  institutions.ror = \"01y9bpm73\", # change the ROR id if you want to analyse the performance of another institution\n  type = \"article\",\n  is_paratext = FALSE,\n  is_retracted = FALSE,\n  from_publication_date = \"2020-01-01\",\n  to_publication_date = \"2024-12-31\",\n  options = list(select = c(\n    \"id\", \"doi\", \"title\", \"publication_year\",\n    \"primary_location\", \"open_access\", \"apc_list\", \"apc_paid\"\n  )),\n  output = \"tibble\",\n  paging = \"cursor\",\n  abstract = FALSE,\n  mailto = \"example@domain.com\" # add your email address here to get into the polite pool\n)"
  },
  {
    "objectID": "OpenAlex.html#structure-of-the-dataset",
    "href": "OpenAlex.html#structure-of-the-dataset",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Structure of the dataset",
    "text": "Structure of the dataset\nTo get an overview of the structure of our data frame, especially the number of rows (observations) and columns (variables), the individual column names and the data types they contain, we will use the glimpse function from the dplyr package, which is part of the tidyverse.\n\nglimpse(df)\n\nRows: 15,952\nColumns: 19\n$ id                          &lt;chr&gt; \"https://openalex.org/W3009912996\", \"https…\n$ title                       &lt;chr&gt; \"SARS-CoV-2 Cell Entry Depends on ACE2 and…\n$ doi                         &lt;chr&gt; \"https://doi.org/10.1016/j.cell.2020.02.05…\n$ publication_year            &lt;int&gt; 2020, 2021, 2020, 2020, 2020, 2020, 2020, …\n$ is_oa                       &lt;lgl&gt; TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n$ is_oa_anywhere              &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE,…\n$ oa_status                   &lt;chr&gt; \"bronze\", \"green\", \"bronze\", \"hybrid\", \"hy…\n$ oa_url                      &lt;chr&gt; \"https://www.cell.com/article/S00928674203…\n$ any_repository_has_fulltext &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE…\n$ source_display_name         &lt;chr&gt; \"Cell\", \"Diabetes Research and Clinical Pr…\n$ source_id                   &lt;chr&gt; \"https://openalex.org/S110447773\", \"https:…\n$ issn_l                      &lt;chr&gt; \"0092-8674\", \"0168-8227\", \"1097-2765\", \"00…\n$ host_organization           &lt;chr&gt; \"https://openalex.org/P4310315673\", \"https…\n$ host_organization_name      &lt;chr&gt; \"Cell Press\", \"Elsevier BV\", \"Elsevier BV\"…\n$ landing_page_url            &lt;chr&gt; \"https://doi.org/10.1016/j.cell.2020.02.05…\n$ pdf_url                     &lt;chr&gt; \"https://www.cell.com/article/S00928674203…\n$ license                     &lt;chr&gt; \"other-oa\", NA, \"other-oa\", \"cc-by\", \"cc-b…\n$ version                     &lt;chr&gt; \"publishedVersion\", NA, \"publishedVersion\"…\n$ apc                         &lt;list&gt; [&lt;data.frame[2 x 5]&gt;], [&lt;data.frame[2 x 5…\n\n\nThe output shows that our data frame contains a total of 15,952 rows (observations) and 19 columns. Furthermore, it shows that most of the column values are of data type character (chr), the publication year column values are of type integer (int), some of the open access column values are of type logical (lgl) and the apc column values are of type list (list). The output also indicates the first values of every column on the right hand side.\nThe first values show us two important things:\n\nThere are at least some missing values within our data frame as is indicated by the NA in the license and version columns. NA is not a common string or numeric value, but a reserved word in R for the logical constant which contains a missing value indicator, i.e. R uses NA to indicate that the specific value is missing.\nThe apc column contains data frames as values. This means we can’t access the apc information directly. We will explore later in the notebook how to transform the column and access the apc information.\n\nTo look at the first 10 rows of our data frame we are using the head function.\n\nhead(df, 10)\n\n# A tibble: 10 × 19\n   id         title doi   publication_year is_oa is_oa_anywhere oa_status oa_url\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;            &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;          &lt;chr&gt;     &lt;chr&gt; \n 1 https://o… SARS… http…             2020 TRUE  TRUE           bronze    https…\n 2 https://o… IDF … http…             2021 FALSE TRUE           green     https…\n 3 https://o… A Mu… http…             2020 TRUE  TRUE           bronze    https…\n 4 https://o… Neur… http…             2020 TRUE  TRUE           hybrid    https…\n 5 https://o… COVI… http…             2020 TRUE  TRUE           hybrid    https…\n 6 https://o… Olfa… http…             2020 TRUE  TRUE           hybrid    https…\n 7 https://o… Mana… http…             2020 TRUE  FALSE          closed    https…\n 8 https://o… SARS… http…             2021 TRUE  TRUE           green     https…\n 9 https://o… Infe… http…             2020 TRUE  TRUE           hybrid    https…\n10 https://o… The … http…             2021 TRUE  TRUE           bronze    https…\n# ℹ 11 more variables: any_repository_has_fulltext &lt;lgl&gt;,\n#   source_display_name &lt;chr&gt;, source_id &lt;chr&gt;, issn_l &lt;chr&gt;,\n#   host_organization &lt;chr&gt;, host_organization_name &lt;chr&gt;,\n#   landing_page_url &lt;chr&gt;, pdf_url &lt;chr&gt;, license &lt;chr&gt;, version &lt;chr&gt;,\n#   apc &lt;list&gt;\n\n\nThe first argument within the head function is our data frame df and the second argument is the number of rows we want to have returned. Each row within our data frame corresponds to an article."
  },
  {
    "objectID": "OpenAlex.html#data-wrangling-with-the-tidyverse",
    "href": "OpenAlex.html#data-wrangling-with-the-tidyverse",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Data wrangling with the tidyverse",
    "text": "Data wrangling with the tidyverse\nBefore analysing the OpenAlex data, we will have a closer look at the publisher and apc columns and perform some data wrangling tasks.\nTo get an overview of the publishers present in our dataframe and the number of articles per publisher, we will use three tidyverse functions and the pipe operator %&gt;% (magrittr pipe) or |&gt; (base R pipe).\nThe pipe operator allows us to take e.g. a data frame or the result of a function and pass it to another function. If we type the name of our data frame followed by the pipe operator that means we don’t have to specify which data we want a function to be performed on, when we call it after the pipe operator.\nThe group_by function allows us to group data in our data frame df by one or more variables. In this case we will group the data frame by the OpenAlex provided id for the publisher in our host_organization column and the publisher name in our host_organization_name column. This allows us to generate aggregate statistics for the publishers in our data frame.\nThe summarise function allows us to calculate summary statistics for each group. In this case we will use the n function to count the number of observations in each group, and the result is stored in a new variable called n.\nThe arrange function is used to sort the data based on the n variable and the desc function lets us determine that the ordering should be in descending order. This means that the groups with the highest number of observations will appear at the top of the output.\n\ndf |&gt;\n  group_by(host_organization, host_organization_name) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n))\n\n# A tibble: 443 × 3\n# Groups:   host_organization [443]\n   host_organization                host_organization_name                     n\n   &lt;chr&gt;                            &lt;chr&gt;                                  &lt;int&gt;\n 1 https://openalex.org/P4310320990 Elsevier BV                             2506\n 2 https://openalex.org/P4310320595 Wiley                                   2121\n 3 https://openalex.org/P4310319900 Springer Science+Business Media         1395\n 4 &lt;NA&gt;                             &lt;NA&gt;                                    1127\n 5 https://openalex.org/P4310310987 Multidisciplinary Digital Publishing …  1073\n 6 https://openalex.org/P4310319908 Nature Portfolio                         650\n 7 https://openalex.org/P4310320527 Frontiers Media                          506\n 8 https://openalex.org/P4310311648 Oxford University Press                  481\n 9 https://openalex.org/P4310319965 Springer Nature                          417\n10 https://openalex.org/P4310320006 American Chemical Society                388\n# ℹ 433 more rows\n\n\nThe output shows us some important things about the data:\n\nThere is a significant amount of articles that don’t have any publisher assigned. We can’t cover data cleaning tasks in-depth in this notebook but want to point out that this is something worth investigating further. Questions that could be asked are: Do these articles have a DOI? Were these articles misclassified in any way? Did the publisher information get lost for some reason? Are there any other inconsistencies with these articles? Can I disregard some or all of the articles?\nPublisher names are at least in some cases not standardized or aggregated to a single publishing house. The approach taken to represent the publishing structure, i.e. listing imprints or subsidiaries separately or under the main publisher name, and the point in time of the analysis, have an influence of the results, e.g. because of changes in ownership (see also Scheidt, 2025).\n\nAs an example we will look at the publisher names in our data frame that contain Springer or Nature. We will use the filter function from the tidyverse that lets us filter articles that fulfil the condition we specify in combination with the grepl function that allows to search for patterns. In this case we will use a regular expression as the pattern to search for.\n\ndf |&gt;\n  group_by(host_organization, host_organization_name) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  filter(grepl(\"^Springer|Nature\", host_organization_name))\n\n# A tibble: 8 × 3\n# Groups:   host_organization [8]\n  host_organization                host_organization_name                n\n  &lt;chr&gt;                            &lt;chr&gt;                             &lt;int&gt;\n1 https://openalex.org/P4310319900 Springer Science+Business Media    1395\n2 https://openalex.org/P4310319908 Nature Portfolio                    650\n3 https://openalex.org/P4310319965 Springer Nature                     417\n4 https://openalex.org/P4310319986 Springer VS                          28\n5 https://openalex.org/P4310320108 Springer Nature (Netherlands)         9\n6 https://openalex.org/P4310319972 Springer International Publishing     3\n7 https://openalex.org/P4310321666 Springer Vienna                       2\n8 https://openalex.org/P4310320090 Springer Medizin                      1\n\n\nIf we want to replace the Springer name variants with Springer Nature as publisher name, we can use the mutate function that lets us transform a column in our data frame in combination with the str_replace_all function that lets us replace string values that follow a pattern we specify to do so.\n\ndf |&gt;\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\")) |&gt;\n  group_by(host_organization_name) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n))\n\n# A tibble: 434 × 2\n   host_organization_name                             n\n   &lt;chr&gt;                                          &lt;int&gt;\n 1 Elsevier BV                                     2506\n 2 Springer Nature                                 2505\n 3 Wiley                                           2121\n 4 &lt;NA&gt;                                            1127\n 5 Multidisciplinary Digital Publishing Institute  1073\n 6 Frontiers Media                                  506\n 7 Oxford University Press                          481\n 8 American Chemical Society                        388\n 9 American Physical Society                        350\n10 Taylor & Francis                                 326\n# ℹ 424 more rows\n\n\nBe aware that this data transformation only applies to the publisher name column and not the OpenAlex provided publisher id column. We would need to perform a separate transformation step to align both. Additionally, we did not permanently rename the publisher name values in our data frame. To do this we can either override our data frame df or create a new data frame by assigning the output with the &lt;- operator.\n\n# overriding our data frame\ndf &lt;- df |&gt;\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\"))\n\n# creating a new data frame df2\ndf2 &lt;- df |&gt;\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\"))\n\nTo access the apc values in our data frame we will use the unnest_wider, unnest_longer, and pivot_wider functions from the tidyverse with the apc column.\nThe unnest_wider function allows us to turn each element of a list-column into a column. We will further use the select function to print only the resulting apc columns.\n\ndf |&gt;\n  unnest_wider(apc, names_sep = \".\") |&gt;\n  select(starts_with(\"apc\"))\n\n# A tibble: 15,952 × 6\n      apc.type   apc.value apc.currency apc.value_usd apc.provenance apc.1\n   &lt;list&lt;chr&gt;&gt; &lt;list&lt;dbl&gt;&gt;  &lt;list&lt;chr&gt;&gt;   &lt;list&lt;dbl&gt;&gt;    &lt;list&lt;chr&gt;&gt; &lt;lgl&gt;\n 1         [2]         [2]          [2]           [2]            [2] NA   \n 2         [2]         [2]          [2]           [2]            [2] NA   \n 3         [2]         [2]          [2]           [2]            [2] NA   \n 4                                                                   NA   \n 5         [2]         [2]          [2]           [2]            [2] NA   \n 6         [2]         [2]          [2]           [2]            [2] NA   \n 7                                                                   NA   \n 8         [2]         [2]          [2]           [2]            [2] NA   \n 9                                                                   NA   \n10         [2]         [2]          [2]           [2]            [2] NA   \n# ℹ 15,942 more rows\n\n\nThe output shows that the values in the apc columns are lists. This is because OpenAlex provides information for APC list prices and prices of APCs that were actually paid, when available. To transform the lists into single value cells we will use the unnest_longer function that does precisely that.\n\ndf |&gt;\n  unnest_wider(apc, names_sep = \".\") |&gt;\n  unnest_longer(c(apc.type, apc.value, apc.currency, apc.value_usd, apc.provenance)) |&gt;\n  select(id, starts_with(\"apc\"))\n\n# A tibble: 22,044 × 7\n   id         apc.type apc.value apc.currency apc.value_usd apc.provenance apc.1\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;          &lt;lgl&gt;\n 1 https://o… list         10100 USD                  10100 &lt;NA&gt;           NA   \n 2 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 3 https://o… list          3970 USD                   3970 &lt;NA&gt;           NA   \n 4 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 5 https://o… list          9080 USD                   9080 &lt;NA&gt;           NA   \n 6 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 7 https://o… list          3690 EUR                   4790 &lt;NA&gt;           NA   \n 8 https://o… paid          3690 EUR                   4790 &lt;NA&gt;           NA   \n 9 https://o… list          9750 EUR                  11690 &lt;NA&gt;           NA   \n10 https://o… paid          9750 EUR                  11690 &lt;NA&gt;           NA   \n# ℹ 22,034 more rows\n\n\nThe output shows that we now have multiple rows for the same id. To transform the data frame to single rows for each id we will use the pivot_wider function that allows us to increase the number of columns and decrease the number of rows.\n\ndf |&gt;\n  unnest_wider(apc, names_sep = \".\") |&gt;\n  unnest_longer(c(apc.type, apc.value, apc.currency, apc.value_usd, apc.provenance)) |&gt;\n  pivot_wider(id_cols = id, names_from = apc.type, values_from = c(apc.value, apc.currency, apc.value_usd, apc.provenance))\n\n# A tibble: 11,022 × 9\n   id          apc.value_list apc.value_paid apc.currency_list apc.currency_paid\n   &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;            \n 1 https://op…          10100             NA USD               &lt;NA&gt;             \n 2 https://op…           3970             NA USD               &lt;NA&gt;             \n 3 https://op…           9080             NA USD               &lt;NA&gt;             \n 4 https://op…           3690           3690 EUR               EUR              \n 5 https://op…           9750           9750 EUR               EUR              \n 6 https://op…          10100             NA USD               &lt;NA&gt;             \n 7 https://op…          10100             NA USD               &lt;NA&gt;             \n 8 https://op…           1800           1800 USD               USD              \n 9 https://op…           9750           9750 EUR               EUR              \n10 https://op…           3920           3920 GBP               GBP              \n# ℹ 11,012 more rows\n# ℹ 4 more variables: apc.value_usd_list &lt;dbl&gt;, apc.value_usd_paid &lt;dbl&gt;,\n#   apc.provenance_list &lt;chr&gt;, apc.provenance_paid &lt;chr&gt;\n\n\nThe output doesn’t show all 9 variables (or columns). Underneath the preview we get the information:\n\n4 more variables: apc.value_usd_list , apc.value_usd_paid , apc.provenance_list , apc.provenance_paid \n\nThis means that they are in fact available in our data frame but are omitted in the preview.\nNow we can access the APC information provided by OpenAlex. In this notebook we won’t analyse APC information any further. If you are interested in APC analysis, we offer a notebook showing how to analyse APC information using the OpenAPC data set at: https://oa-datenpraxis.de/OpenAPC.html"
  },
  {
    "objectID": "OpenAlex.html#analysing-institutional-open-access-performance",
    "href": "OpenAlex.html#analysing-institutional-open-access-performance",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Analysing institutional open access performance",
    "text": "Analysing institutional open access performance\nIn the following sections, we will analyse the data to address our question and generate visualizations. This notebook can’t provide an in-depth analysis, but it will demonstrate how to apply some useful functions from base R and the tidyverse to gain insights from the data and show how to create visualisations using the ggplot2 package (Wickham, 2016).\nHow many of the institutions publication are open access?\nTo determine total number of open access publications of the research organization, we are using the sum function on the is_oa column. This column contains boolean values (true or false) and the sum function will sum up all rows that contain true values.\n\nsum(df$is_oa, na.rm = T)\n\n[1] 10668\n\n\nWe also provided the na.rm=T argument to the sum function which causes NA values to be removed.\nWhen we check for NA values in the is_oa column using the is.na function, we see that there are 21 articles where the open access status is not determined.\n\nsum(is.na(df$is_oa))\n\n[1] 21\n\n\nTo determine the overall open access share over all publication years in our data frame, we divide the total number of open access publications by the total number of publications. We calculate the latter using the n_distinct function on our id column. The n_distinct function is quite handy as it returns the number of unique values in the provided column. Since we provide the id column, it will return the total number of publications in our data frame.\n\nround(sum(df$is_oa, na.rm = T) / n_distinct(df$id) * 100, 2)\n\n[1] 66.88"
  },
  {
    "objectID": "OpenAlex.html#how-are-open-access-publications-distributed-across-journals",
    "href": "OpenAlex.html#how-are-open-access-publications-distributed-across-journals",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "How are open access publications distributed across journals?",
    "text": "How are open access publications distributed across journals?\nTo analyse the distribution of open access articles across journals we will calculate the total number of articles (n_articles), the total number of open access articles (n_oa_articles) and the total number of closed articles (n_closed_articles) per journal. We will again use the group_by, summarise and arrange functions. However, since we noticed that 21 articles have an undetermined open access status, we will first filter out all rows with NA values in the is_oa column. We will also group the data by the source_display_name column to generate aggregate statistics for the journals.\n\ndf |&gt;\n  filter(!is.na(is_oa)) |&gt;\n  group_by(source_display_name) |&gt;\n  summarise(\n    n_articles = n(),\n    n_oa_articles = sum(is_oa),\n    n_closed_articles = n_articles - n_oa_articles\n  ) |&gt;\n  arrange(desc(n_oa_articles))\n\n# A tibble: 4,156 × 4\n   source_display_name                n_articles n_oa_articles n_closed_articles\n   &lt;chr&gt;                                   &lt;int&gt;         &lt;int&gt;             &lt;int&gt;\n 1 Scientific Reports                        221           221                 0\n 2 Astronomy and Astrophysics                219           215                 4\n 3 Journal of High Energy Physics            173           173                 0\n 4 Nature Communications                     170           170                 0\n 5 PLoS ONE                                  124           123                 1\n 6 The European Physical Journal C            97            97                 0\n 7 Forests                                    95            95                 0\n 8 Angewandte Chemie                         103            92                11\n 9 International Journal of Molecula…         84            84                 0\n10 &lt;NA&gt;                                      414            84               330\n# ℹ 4,146 more rows\n\n\nThe results show that 414 articles have no journal assigned within our data frame. This could indicate that more data cleaning needs to be performed. The results further show that the top three journals in terms of open access publication volume are Scientific Reports, Astronomy and Astrophysics, and Journal of High Energy Physics.\nWe can further explore the open access status distribution for the articles. We will do this on the example of the top three journals in terms of open access publication volume.\n\ndf |&gt;\n  filter(source_display_name %in% c(\"Scientific Reports\", \"Astronomy and Astrophysics\", \"Journal of High Energy Physics\")) |&gt;\n  group_by(source_display_name, is_oa, oa_status) |&gt;\n  summarise(n = n())\n\n# A tibble: 8 × 4\n# Groups:   source_display_name, is_oa [4]\n  source_display_name            is_oa oa_status     n\n  &lt;chr&gt;                          &lt;lgl&gt; &lt;chr&gt;     &lt;int&gt;\n1 Astronomy and Astrophysics     FALSE closed        1\n2 Astronomy and Astrophysics     FALSE green         3\n3 Astronomy and Astrophysics     TRUE  bronze       95\n4 Astronomy and Astrophysics     TRUE  green         1\n5 Astronomy and Astrophysics     TRUE  hybrid      119\n6 Journal of High Energy Physics TRUE  diamond     168\n7 Journal of High Energy Physics TRUE  green         5\n8 Scientific Reports             TRUE  gold        221\n\n\nThe results show that there are some data inconsistencies for the Astronomy and Astrophysics journal regarding the green open access status. Furthermore Scientific Reports appears to be a true gold open access journal.\nHow does the number of open access publications evolve over time?\nWe can combine functions from the tidyverse and ggplot2 to visualise the development of open access over time.\nFirst, we group the data by publication year and open access status. We will then compute the number of articles in each group. In the ggplot function, we assign the publication year column to the x axis and the number of articles to the y axis. We choose point (geom_point) and line (geom_line) graph types to mark the distinct values of n and have them connected by lines. Both are provided with a colour aesthetic which is set to our open access status column. This will result in different colours being assigned to the points and lines for the different open access status values. With the theme_minimal option we are applying a minimal theme for the plot appearance.\n\ndf |&gt;\n  group_by(publication_year, oa_status) |&gt;\n  summarise(n = n(), .groups = \"keep\") |&gt;\n  ggplot(aes(x = publication_year, y = n)) +\n  geom_line(aes(colour = oa_status)) +\n  geom_point(aes(colour = oa_status)) +\n  theme_minimal()\n\n\n\n\n\n\n\nThe plot shows use the total number of publications for each publication year and open access status. Generally, there seems to be a downwards trend in terms of publication volume for all open access status types but hybrid open access.\nWe can further choose to visualise the open access distribution over time in terms of percentages. For this we first calculate the share of each open access status per publication year and create a new column using the mutate function that stores these values. We pipe the result through to the ggplot function assigning the publication year column to the x axis and the share to the y axis. We assign the oa_status column to the fill argument which will plot a different colour for each open access status. For this plot we choose a bar chart (geom_bar) graph type and again apply the minimal theme.\n\ndf |&gt;\n  group_by(publication_year, oa_status) |&gt;\n  summarise(count = n()) |&gt;\n  mutate(perc = count / sum(count) * 100) |&gt;\n  ggplot(aes(x = publication_year, y = perc, fill = oa_status)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal()\n\n\n\n\n\n\n\nThe plot shows use the share of each open access status for each publication year. The most dominant open access types are gold and hybrid open access. Furthermore the share of open access publications across all publication years is higher than for closed access publications."
  },
  {
    "objectID": "OpenAlex.html#exercises",
    "href": "OpenAlex.html#exercises",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Exercises",
    "text": "Exercises\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe following exercises focus on open access publications in regard to publishers and journals. The code is presented in interactive code blocks. You can adapt the code and run it by clicking on run code."
  },
  {
    "objectID": "OpenAlex.html#aggregate-statistics-for-publishers",
    "href": "OpenAlex.html#aggregate-statistics-for-publishers",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Aggregate statistics for publishers",
    "text": "Aggregate statistics for publishers\nBefore, we analysed the distribution of open access articles across journals. Below is a copy of the corresponding code. Adapt the code to give you aggregate statistics for publishers instead of journals.\n\n\n Interactive editor\n Solution\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhich publishers are among the top three in terms of overall publication volume and in terms of open access publication volume? Do you notice any interesting patterns?"
  },
  {
    "objectID": "OpenAlex.html#visuzlisation-of-open-access-disctribution-by-top-three-publishers",
    "href": "OpenAlex.html#visuzlisation-of-open-access-disctribution-by-top-three-publishers",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Visuzlisation of open access disctribution by top three publishers",
    "text": "Visuzlisation of open access disctribution by top three publishers\nNow, see if you can adapt the code we used to visualise the open access share over time to show you the open access share for the top three publishers in terms of open access publication volume.\n\n\n Interactive editor\n Hint\n Solution\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint: You’ll want to change something in the code so that you filter first based on the publisher names of the top three publishers before you perform the grouping. You can reuse code that was already introduced in the notebook.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "OpenAlex.html#footnotes",
    "href": "OpenAlex.html#footnotes",
    "title": "Open Access Monitoring with OpenAlex",
    "section": "Footnotes",
    "text": "Footnotes\n\nAPI stands for Application Programming Interface. An API call is a request made by a client to an API endpoint on a server to retrieve or send information. An API call is a way for different applications to communicate with each other. The client (e.g. you, the user) makes the request and the server sends back a response (e.g. the OpenAlex data you requested).↩︎\nOpenAlex sorts API users into two pools: the polite and the common pool. All users who identify by providing their email addresses, i.e. are being polite and telling OpenAlex who you are and how to contact you if there happens to be any problems, are sorted into the polite pool, which has more consistent response times.↩︎"
  },
  {
    "objectID": "datenschutz.html",
    "href": "datenschutz.html",
    "title": "Privacy Statement",
    "section": "",
    "text": "We do not automatically or manually collect, store or process any personal data.\nThis website contains links or buttons that lead to third-party services like Mastodon or email. Use of these features may result in data collection. Engaging with these buttons, tools, or content may automatically send certain browser information to the service provider. Please review the privacy statements of the service providers for more information.\nThis website is hosted on GitHub Pages. GitHub may collect personal data when interacting with their services, for more information please review the GitHub Privacy Statement.\nFor more information, see the Data Protection Statement of Humboldt-Universität zu Berlin.\n\n\n\n Back to top"
  },
  {
    "objectID": "aps/AP3.html#description",
    "href": "aps/AP3.html#description",
    "title": "WP 3 Open Access in institutional Rankings",
    "section": "Description",
    "text": "Description\nInstitutional rankings enjoy a high level of attention among science policy decision-makers and the public because they succeed in comparing scientific institutions with each other in a generally understandable and clear manner. Despite numerous points of criticism, rankings can therefore not be ignored as a measure of the perception of academic institutions and play a corresponding role in institutional information management.\nWP 3 takes into account that OA is increasingly appearing as a comparative dimension in rankings, for example in the Leiden Ranking of the CWTS, the COKI Open Access Dashboard and the Scimago Institutions Ranking."
  },
  {
    "objectID": "aps/AP5.html#description",
    "href": "aps/AP5.html#description",
    "title": "WP 5 Synopsis",
    "section": "Description",
    "text": "Description\nA common understanding of science-led data practice is a prerequisite for shaping the OA transformation. This practice includes the handling of data in scientific institutions in general (WP 1), the analysis and evaluation of data in the context of publishing contracts (WP 2), the handling of data on OA in institutional rankings (WP 3) and the collection of data on OA for reporting (WP 4). In line with the aim of ensuring data sovereignty in science, a synopsis will be created in WP 5 based on the findings of WPs 1, 2, 3 and 4. Recommendations (T5.2) are formulated on the basis of this synopsis (T5.1). The aim is to summarise the findings of the previous WPs and to work out their strategic dimension. As a result, summarised recommendations are published (T5.3), which are aimed at decision-makers in universities, non-university research institutions, funding organisations and science policy. Of particular importance here is the integrative view, which summarises the work in the project and highlights the interactions between the WPs. Current science policy recommendations (e.g. from the Alliance, EU, UNESCO, WR, Science Europe) are also placed in relation to the results of the previous WPs. This WP thus acts as an impulse for the future organisation of the OA transformation."
  },
  {
    "objectID": "aps/AP8.html#description",
    "href": "aps/AP8.html#description",
    "title": "WP 8 Networks",
    "section": "Description",
    "text": "Description\nWork with data on OA transformation is often carried out by various stakeholders in an academic institution. For example, professionals such as OA officers, librarians in acquisitions and licensing, research officers and actors in the field of research funding deal with aspects of data work relating to OA. The aim of the WP is to facilitate dialogue on defined issues beyond professional profiles and thus actively enable inter- and transdisciplinary discourse on data work relating to OA. The project initiates the networks and organises them with three digital workshops each over the course of the project. In addition, a mailing list will be organised for the networks, thus providing an impetus for longer-term cooperation. At the end of the project, it will be determined with other stakeholders, such as the Conference of Information and Library Science Training and Study Programmes (KIBA), to what extent the topics discussed can be continued in other committees and networks."
  },
  {
    "objectID": "aps/AP7.html#description",
    "href": "aps/AP7.html#description",
    "title": "WP 7 Tools",
    "section": "Description",
    "text": "Description\nThere is now a wide range of tools for collecting, analysing and visualising data relating to the OA transformation. In addition to the already established services such as the Hybrid Open Access Dashboard (HOAD), OpenAPC and Open Access Monitor, these include, for example\n\nAPI clients for computer-aided access to open data sources (e.g. clients from rOpenSci for publication analyses with R)\nPaid tools such as Unsub, a tool for libraries to evaluate publishing offers based on local usage data.\nPaid tools such as ChronosHub, Oable, OAMetrix and OA Switchboard for APC management.\nDashboards for data visualisation such as the COKI Open Access Dashboard, the Charité Open Access Dashboard and the Hamburg Open Science Dashboard.\n\nAs there is currently no overview of these diverse tools and there are no systematic training and further education and further training procedures in the field of Scholarly Communication Analytics, a digital toolbox is to be developed in WP 5. This will provide information on tools for data work relating to OA transformation. Based on research, the tools will be described by a metadata schema to be developed. metadata schema to be developed. This schema should support the findability and evaluation of the tools. tools. The resulting toolbox will be presented on the project website. After the end of the curation will be continued by the Helmholtz Open Science Office. The toolbox will be operated in English language."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Strecker, D., Pampel, H., & Höfting, J. (2026). Pursuing transparency: How research performing organizations in Germany collect data on publication costs. arXiv. https://doi.org/10.48550/ARXIV.2601.08340\n\n\nFerguson, L. M., Pampel, H., Strecker, D., & Meistring, M. (2025). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. Zenodo. https://doi.org/10.5281/zenodo.14505423\n\n\nInformationsbudget, F. (2025). Fokusgruppe Informationsbudget: Marktplatz. https://doi.org/10.5281/zenodo.17692418\n\n\nJahn, N. (2025a). Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata. Scientometrics. https://doi.org/10.1007/s11192-025-05390-3\n\n\nJahn, N. (2025b). How open are hybrid journals included in transformative agreements? Quantitative Science Studies, 6, 242–262. https://doi.org/10.1162/qss_a_00348\n\n\nOberländer, A. (2025). OA Datenpraxis Webinar: Leiden Ranking at the University of Konstanz. https://doi.org/10.5281/zenodo.15593872\n\n\nPampel, H., Stein, L.-M., Mittermaier, B., Strecker, D., Schweighofer, B., & Deinzer, G. (2025). Praktiken und Infrastrukturen des Open-Access-Monitorings. In Research Group Information Management @ Humboldt-Universität zu Berlin. https://doi.org/10.59350/g6jdg-ejp06\n\n\nSchneider, J., & Pampel, H. (2025a). Mapping the Landscape of Open Access Dashboards - A Dataset for Research and Infrastructure Development. arXiv. https://doi.org/10.48550/arXiv.2512.01669\n\n\nSchneider, J., & Pampel, H. (2025b). Open-Access-Dashboards im Überblick. https://doi.org/10.5281/zenodo.17131040\n\n\nSchneider, J., Pampel, H., & Höfting, J. (2025). Data Documentation for: Mapping the Landscape of Open Access Dashboards: A Dataset for Research and Infrastructure Development. Zenodo. https://doi.org/10.5281/zenodo.15593821\n\n\nStrecker, D., & Dörner, S. (2025). Open Access Monitoring and Open Research Information (N. McGregor, Ed.). LIBER. https://doi.org/10.23636/dwcn-x827\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025a). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.17119308\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025b). Wie erfassen wissenschaftliche Einrichtungen Daten zu Publikationskosten? In oa.blog. https://open-access.network/blog/wie-erfassen-wissenschaftliche-einrichtungen-daten-zu-publikationskosten\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025c). Dataset for: Recording of publication costs at research performing institutions in Germany. Zenodo. https://doi.org/10.5281/zenodo.14732554\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025d). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://nbn-resolving.org/urn:nbn:de:0290-opus4-198024\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025e). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. Bibliothek Forschung Und Praxis. https://doi.org/10.1515/bfp-2025-0008\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025f). OA Datenpraxis Webinar: Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.15076512\n\n\nVan Eck, N. J. (2025). OA Datenpraxis Webinar: CWTS Leiden Ranking Open Edition. https://doi.org/10.5281/zenodo.15147838\n\n\nBarbers, I., Kindling, M., Stadler, H., & Strecker, D. (2024). Stand und Perspektive des Open-Access-Reportings. https://doi.org/10.5281/zenodo.13831942\n\n\nFerguson, L. M., Meistring, M., Pampel, H., & Strecker, D. (2024). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. https://doi.org/10.5281/zenodo.13837272\n\n\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/ZENODO.10794298"
  },
  {
    "objectID": "publications.html#publications-from-the-project",
    "href": "publications.html#publications-from-the-project",
    "title": "Publications",
    "section": "",
    "text": "Strecker, D., Pampel, H., & Höfting, J. (2026). Pursuing transparency: How research performing organizations in Germany collect data on publication costs. arXiv. https://doi.org/10.48550/ARXIV.2601.08340\n\n\nFerguson, L. M., Pampel, H., Strecker, D., & Meistring, M. (2025). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. Zenodo. https://doi.org/10.5281/zenodo.14505423\n\n\nInformationsbudget, F. (2025). Fokusgruppe Informationsbudget: Marktplatz. https://doi.org/10.5281/zenodo.17692418\n\n\nJahn, N. (2025a). Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata. Scientometrics. https://doi.org/10.1007/s11192-025-05390-3\n\n\nJahn, N. (2025b). How open are hybrid journals included in transformative agreements? Quantitative Science Studies, 6, 242–262. https://doi.org/10.1162/qss_a_00348\n\n\nOberländer, A. (2025). OA Datenpraxis Webinar: Leiden Ranking at the University of Konstanz. https://doi.org/10.5281/zenodo.15593872\n\n\nPampel, H., Stein, L.-M., Mittermaier, B., Strecker, D., Schweighofer, B., & Deinzer, G. (2025). Praktiken und Infrastrukturen des Open-Access-Monitorings. In Research Group Information Management @ Humboldt-Universität zu Berlin. https://doi.org/10.59350/g6jdg-ejp06\n\n\nSchneider, J., & Pampel, H. (2025a). Mapping the Landscape of Open Access Dashboards - A Dataset for Research and Infrastructure Development. arXiv. https://doi.org/10.48550/arXiv.2512.01669\n\n\nSchneider, J., & Pampel, H. (2025b). Open-Access-Dashboards im Überblick. https://doi.org/10.5281/zenodo.17131040\n\n\nSchneider, J., Pampel, H., & Höfting, J. (2025). Data Documentation for: Mapping the Landscape of Open Access Dashboards: A Dataset for Research and Infrastructure Development. Zenodo. https://doi.org/10.5281/zenodo.15593821\n\n\nStrecker, D., & Dörner, S. (2025). Open Access Monitoring and Open Research Information (N. McGregor, Ed.). LIBER. https://doi.org/10.23636/dwcn-x827\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025a). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.17119308\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025b). Wie erfassen wissenschaftliche Einrichtungen Daten zu Publikationskosten? In oa.blog. https://open-access.network/blog/wie-erfassen-wissenschaftliche-einrichtungen-daten-zu-publikationskosten\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025c). Dataset for: Recording of publication costs at research performing institutions in Germany. Zenodo. https://doi.org/10.5281/zenodo.14732554\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025d). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://nbn-resolving.org/urn:nbn:de:0290-opus4-198024\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025e). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. Bibliothek Forschung Und Praxis. https://doi.org/10.1515/bfp-2025-0008\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025f). OA Datenpraxis Webinar: Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.15076512\n\n\nVan Eck, N. J. (2025). OA Datenpraxis Webinar: CWTS Leiden Ranking Open Edition. https://doi.org/10.5281/zenodo.15147838\n\n\nBarbers, I., Kindling, M., Stadler, H., & Strecker, D. (2024). Stand und Perspektive des Open-Access-Reportings. https://doi.org/10.5281/zenodo.13831942\n\n\nFerguson, L. M., Meistring, M., Pampel, H., & Strecker, D. (2024). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. https://doi.org/10.5281/zenodo.13837272\n\n\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/ZENODO.10794298"
  },
  {
    "objectID": "publications.html#preliminary-work-of-the-project-partners",
    "href": "publications.html#preliminary-work-of-the-project-partners",
    "title": "Publications",
    "section": "Preliminary work of the project partners",
    "text": "Preliminary work of the project partners\n\n\nJahn, N. (2024). How open are hybrid journals included in transformative agreements? arXiv. https://doi.org/10.48550/arXiv.2402.18255\n\n\nFraser, N., Hobert, A., Jahn, N., Mayr, P., & Peters, I. (2023). No deal: German researchers’ publishing and citing behaviors after big deal negotiations with elsevier. Quantitative Science Studies, 4(2), 325–352. https://doi.org/10.1162/qss_a_00255\n\n\nTaubert, N., Hobert, A., Jahn, N., Bruns, A., & Iravani, E. (2023). Understanding differences of the OA uptake within the german university landscape (2010–2020): Part 1—journal-based OA. Scientometrics, 128(6), 3601–3625. https://doi.org/10.1007/s11192-023-04716-3\n\n\nJahn, N., Matthias, L., & Laakso, M. (2022). Toward transparency of hybrid open access through publisher-provided metadata: An article-level study of elsevier. Journal of the Association for Information Science and Technology, 73(1), 104–118. https://doi.org/10.1002/asi.24549\n\n\nPampel, H. (2022). From library budget to information budget: Fostering transparency in the transformation towards open access. Insights the UKSG Journal, 35, 8. https://doi.org/10.1629/uksg.576\n\n\nHobert, A., Jahn, N., Mayr, P., Schmidt, B., & Taubert, N. (2021). Open access uptake in germany 2010–2018: Adoption in a diverse research landscape. Scientometrics, 126(12), 9751–9777. https://doi.org/10.1007/s11192-021-04002-0"
  },
  {
    "objectID": "dashboard_uebersicht.html",
    "href": "dashboard_uebersicht.html",
    "title": "OA Dashboards Contact",
    "section": "",
    "text": "With Open Access gaining importance in science policy, questions arise about its share in the publication output of research institutions, countries, and globally. In the OA Data Practices project, we are developing an overview of dashboards on Open Access.\nTo support this, we conducted a search for relevant dashboards and created a custom metadata schema to index them. In May 2025, we launched a community process to further develop and expand the collection.\nYou can find the Open Access dashboard collection here and the corresponding metadata schema here.\nIf you have any suggestions for modifications or a new dashboard that isn’t listed here yet, we encourage you to write us here: oa-datenpraxis-dashboards@listserv.dfn.de. We are happy about any suggestions and will add new dashboards for you.\nIf you want to become active yourself you can find an editable version of the dashboard collection here: https://nextcloud.gfz.de/s/QG38J6kEDbJ8DXz There you can add your new suggestions yourself."
  },
  {
    "objectID": "dashboard_uebersicht.html#oa-dashboard-collection",
    "href": "dashboard_uebersicht.html#oa-dashboard-collection",
    "title": "OA Dashboards Contact",
    "section": "",
    "text": "With Open Access gaining importance in science policy, questions arise about its share in the publication output of research institutions, countries, and globally. In the OA Data Practices project, we are developing an overview of dashboards on Open Access.\nTo support this, we conducted a search for relevant dashboards and created a custom metadata schema to index them. In May 2025, we launched a community process to further develop and expand the collection.\nYou can find the Open Access dashboard collection here and the corresponding metadata schema here.\nIf you have any suggestions for modifications or a new dashboard that isn’t listed here yet, we encourage you to write us here: oa-datenpraxis-dashboards@listserv.dfn.de. We are happy about any suggestions and will add new dashboards for you.\nIf you want to become active yourself you can find an editable version of the dashboard collection here: https://nextcloud.gfz.de/s/QG38J6kEDbJ8DXz There you can add your new suggestions yourself."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "The project OA Datenpraxis supports the development of structures for the open access transformation at research institutions in Germany. The focus is on promoting and establishing processes and procedures for sovereign data practice in shaping the open access transformation.\nThe project supports practitioners in administration, libraries and other service institutions in professionalizing their data practices by promoting the organization, networking and standardization of processes through a coordinated approach.\n\n\nWith regard to the open access transformation, the project pursues the following objectives:\n\nimproving data-driven administration\nstrengthening collaborations\ndeveloping standards for collaborative data practices\nminimizing dependencies on commercial data sources\nimproving information services\n\nThrough surveys, analyses, validations and operational recommendations, OA Datenpraxis makes a central contribution to the future development of supra-regional availability of information in Germany.\n\n\n\nThe public section of the project proposal is accessible here (in German):\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/zenodo.10794298\n\n\n\nThe project OA Datenpraxis with the project number 528466070 is funded by the German Research Foundation DFG."
  },
  {
    "objectID": "index.html#project-description",
    "href": "index.html#project-description",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "The project OA Datenpraxis supports the development of structures for the open access transformation at research institutions in Germany. The focus is on promoting and establishing processes and procedures for sovereign data practice in shaping the open access transformation.\nThe project supports practitioners in administration, libraries and other service institutions in professionalizing their data practices by promoting the organization, networking and standardization of processes through a coordinated approach.\n\n\nWith regard to the open access transformation, the project pursues the following objectives:\n\nimproving data-driven administration\nstrengthening collaborations\ndeveloping standards for collaborative data practices\nminimizing dependencies on commercial data sources\nimproving information services\n\nThrough surveys, analyses, validations and operational recommendations, OA Datenpraxis makes a central contribution to the future development of supra-regional availability of information in Germany.\n\n\n\nThe public section of the project proposal is accessible here (in German):\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/zenodo.10794298\n\n\n\nThe project OA Datenpraxis with the project number 528466070 is funded by the German Research Foundation DFG."
  },
  {
    "objectID": "events/webinar_20250328.html",
    "href": "events/webinar_20250328.html",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Date: 28.03.2025\nTime: 10:00–11:00 AM CET\nLocation: Online via Zoom\nRegistrtration: https://hu-berlin.zoom-x.de/webinar/register/WN_pKTlDzjsQwC7QspLxwMHCg"
  },
  {
    "objectID": "events/webinar_20250328.html#dates",
    "href": "events/webinar_20250328.html#dates",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Date: 28.03.2025\nTime: 10:00–11:00 AM CET\nLocation: Online via Zoom\nRegistrtration: https://hu-berlin.zoom-x.de/webinar/register/WN_pKTlDzjsQwC7QspLxwMHCg"
  },
  {
    "objectID": "events/webinar_20250328.html#description",
    "href": "events/webinar_20250328.html#description",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "Description",
    "text": "Description\nThe webinar will present the results of a survey conducted as part of the OA Datenpraxis project funded by the German Research Foundation (DFG) in 2024.\nThe survey, which was developed in dialogue with representatives of the DEAL subgroup ‘Communication’, investigated how data on publication costs are currently collected at scientific institutions in Germany. Representatives of universities, universities of applied sciences, institutes of non-university research organisations and federal departmental research institutions were addressed. Of the 583 people invited, 258 (44.3 %) took part in the survey. The survey is the first comprehensive survey on publication costs in Germany.\nThis webinar is aimed at professionals who are interested in open access monitoring, in particular the recording of open access publication costs.\n\nProgramme\nAfter a presentation of the survey results, participants will have the opportunity to ask questions about the survey. This will be followed by a panel discussion with members of the DEAL group on some key aspects of recording publication costs.\n\nWelcome by Heinz Pampel (5 minutes)\nPresentation of the survey results by Dorothea Strecker (30 minutes)\nQ&A on the survey (10 minutes)\nPanel discussion with members of the DEAL Group (15 minutes)"
  },
  {
    "objectID": "events/bid25_20250624.html",
    "href": "events/bid25_20250624.html",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "",
    "text": "Date: 24.06.2025\nTime: 16:00–18:00 CEST\nRoom: Salon London\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250624.html#dates",
    "href": "events/bid25_20250624.html#dates",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "",
    "text": "Date: 24.06.2025\nTime: 16:00–18:00 CEST\nRoom: Salon London\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250624.html#description",
    "href": "events/bid25_20250624.html#description",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "Description",
    "text": "Description\nThe aim of the hands-on lab is to provide a low-threshold practical introduction to the creation of a simple dashboard for visualising the (open access) publication output of academic institutions. For this purpose, Quarto, a scientific and technical open-source publication system, will be used, which makes it possible to create reproducible articles, presentations, dashboards, websites, blogs or books in various (export) formats. The aim is the clear and easily retrievable presentation of different OA-related data and a contribution to a reproducible OA data practice, which is also being strived for and expanded as part of the OA Datenpraxis1 project. At the beginning, a dataset for the own institution is retrieved from OpenAlex2. The basics of using Quarto to load and edit data, create visualisations and present the results in a user-friendly dashboard with R will then be developed together. Previous knowledge of the R programming language or how to use Quarto is not required, but is helpful. The code used in the lab will be developed in such a way that it can be used and understood without prior knowledge. Please bring a laptop and create a Posit Cloud account3 in advance."
  },
  {
    "objectID": "events/bid25_20250624.html#footnotes",
    "href": "events/bid25_20250624.html#footnotes",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://oa-datenpraxis.de/↩︎\nhttps://openalex.org/↩︎\nhttps://posit.cloud/plans/free↩︎"
  },
  {
    "objectID": "events/webinar_20250404.html",
    "href": "events/webinar_20250404.html",
    "title": "OA Datenpraxis Webinar  Open metadata for university rankings illustrated by the Leiden Ranking",
    "section": "",
    "text": "Date: 04.04.2025\nTime: 10:00–11:00 AM CEST\nLocation: Online via Zoom\nRegistration: https://hu-berlin.zoom-x.de/webinar/register/WN_4_U1o0yDSbOufyh7y_aloQ"
  },
  {
    "objectID": "events/webinar_20250404.html#dates",
    "href": "events/webinar_20250404.html#dates",
    "title": "OA Datenpraxis Webinar  Open metadata for university rankings illustrated by the Leiden Ranking",
    "section": "",
    "text": "Date: 04.04.2025\nTime: 10:00–11:00 AM CEST\nLocation: Online via Zoom\nRegistration: https://hu-berlin.zoom-x.de/webinar/register/WN_4_U1o0yDSbOufyh7y_aloQ"
  },
  {
    "objectID": "events/webinar_20250404.html#description",
    "href": "events/webinar_20250404.html#description",
    "title": "OA Datenpraxis Webinar  Open metadata for university rankings illustrated by the Leiden Ranking",
    "section": "Description",
    "text": "Description\nOpen metadata on scientific publications increasingly play an important role in university rankings. They not only enable comprehensive and transparent reporting on the research performance of universities, but also offer a wide range of reuse options.\nThe webinar will present the Leiden Ranking of the CWTS, which now also utilises open metadata. The example of the University of Konstanz will then be used to illustrate how universities can use the ranking to provide data-supported information about the research and open access achievements of their institution both internally and externally.\nWe are delighted that Dr Nees Jan van Eck (CWTS Leiden) and Dr Anja Oberländer (University of Konstanz) will be sharing their insights with us, both from the perspective of creating a ranking and from the application perspective.\nThis webinar is aimed at all employees in the field of Open Access/Open Science and heads of scientific institutions, as well as people interested in science assessment and Open Access/Open Science.\n\nProgramme:\n\nWelcome by Sophia Dörner (5 minutes)\nPresentation 1: Nees Jan van Eck (CWTS Leiden) introduces the Leiden Ranking Open Edition with a focus on open data and open access as a ranking dimension (20 minutes).\nPresentation 2: Anja Oberländer (University of Konstanz) provides a user perspective on the Leiden Ranking and discusses strategic approaches to Open Access/Open Science (20 minutes).\nQ&A Session (15 minutes)."
  },
  {
    "objectID": "events/oat25_20250919.html",
    "href": "events/oat25_20250919.html",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "",
    "text": "Date: 19.09.2025\nTime: 09:00–10:30 AM CEST\nRoom: Room C425\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/oat25_20250919.html#dates",
    "href": "events/oat25_20250919.html#dates",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "",
    "text": "Date: 19.09.2025\nTime: 09:00–10:30 AM CEST\nRoom: Room C425\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/oat25_20250919.html#description",
    "href": "events/oat25_20250919.html#description",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "Description",
    "text": "Description\nThe term “open access monitoring” refers to the collection and analysis of information, publications, costs, and other parameters related to open access publishing. With regards to the objectives and economic dimension of the open access transformation, the handling of this information is becoming increasingly relevant.\nThis workshop is organized by the DFG-funded projects OA Datenpraxis 1, openCost 2, and Transform2Open 3 and is aimed at professionals involved in monitoring.\nThe aim of the workshop is to discuss current issues relating to open access monitoring with participants. The workshop will focus on the following areas: (1) strengthening standardization in the field of monitoring, (2) promoting transparency initiatives, (3)developing the potential for reusing open data – also in the context of the Barcelona Declaration.\nThe workshop begins with a brief introduction of the projects. Participants then discuss issues related to the above-mentioned aspects in groups at different stations in the room, following the World Café format. The results are then summarised in the plenary. Etherpads will be used to collaboratively record results. Following the event, the organizers will communicate the results in a blog post.\nA maximum of 30 people can participate in the workshop. Participants are advised to bring their own laptop."
  },
  {
    "objectID": "events/oat25_20250919.html#footnotes",
    "href": "events/oat25_20250919.html#footnotes",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://oa-datenpraxis.de↩︎\nhttps://www.opencost.de↩︎\nhttps://www.transform2open.de↩︎"
  },
  {
    "objectID": "events.html#conferences-meetings",
    "href": "events.html#conferences-meetings",
    "title": "Events",
    "section": "Conferences & Meetings",
    "text": "Conferences & Meetings"
  },
  {
    "objectID": "events/bid25_20250626.html",
    "href": "events/bid25_20250626.html",
    "title": "Presentation  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "",
    "text": "Date: 26.06.2025\nTime: 11:00 AM to 12:30 PM CEST\nRoom: Kaisen Saal (with Streaming)\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250626.html#dates",
    "href": "events/bid25_20250626.html#dates",
    "title": "Presentation  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "",
    "text": "Date: 26.06.2025\nTime: 11:00 AM to 12:30 PM CEST\nRoom: Kaisen Saal (with Streaming)\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250626.html#description",
    "href": "events/bid25_20250626.html#description",
    "title": "Presentation  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "Description",
    "text": "Description\nThe Georg-August-Universität Göttingen signed the Barcelona Declaration on Open Research Information on 28 August 2024. In doing so, the University of Göttingen is joining renowned international scientific actors who are committed to opening up research information.\nThe presentation will first briefly present the fields of action of the Göttingen State and University Library in line with the principles of the Barcelona Declaration. The presentation will then focus on the evaluation of the applicability of open metadata of scientific publications for the monitoring of international Open Access transformative agreements in comparison to proprietary bibliometric databases. The data analysis of more than 13,000 hybrid scientific journals, which are part of a transformative agreements, from the open sources Crossref and OpenAlex as well as the closed databases Web of Science and Scopus shows potentials and gaps. Building on this, fields of action for the expansion of open metadata are identified, which libraries and publishers can address in the context of negotiations on open access transformative agreements. Overall, open access transformative agreements play a key role in improving open access monitoring through the provision of open metadata by publishers and thus promoting the shift towards open research information in line with the Barcelona Declaration."
  },
  {
    "objectID": "events/bid25_20250627.html",
    "href": "events/bid25_20250627.html",
    "title": "Presentation  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Date: 27.06.2025\nTime: 11:00–11:30 AM CEST\nRoom: Focke-Wulf Saal\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250627.html#dates",
    "href": "events/bid25_20250627.html#dates",
    "title": "Presentation  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Date: 27.06.2025\nTime: 11:00–11:30 AM CEST\nRoom: Focke-Wulf Saal\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/bid25_20250627.html#description",
    "href": "events/bid25_20250627.html#description",
    "title": "Presentation  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "Description",
    "text": "Description\nData on publications and costs are required for the strategic and operational design of the open access transformation. The presentation presents the results of a survey conducted as part of the OA Datenpraxis project funded by the German Research Foundation (DFG) in 2024. The survey investigated how data on publication costs are currently recorded at scientific institutions in Germany. Representatives of universities, universities of applied sciences, institutes of non-university research organisations (Fraunhofer-Gesellschaft, Helmholtz Association, Leibniz Association and Max Planck Society) and federal departmental research institutions were addressed. Of the 583 people invited, 258 (44.3 %) completed the questionnaire. The survey is the first comprehensive survey to record publication costs in Germany.\nThe results show that the majority of respondents at least partially record publication costs. However, the processes are not regulated in a binding manner everywhere. 33.1% of respondents stated that publication costs are recorded decentrally in several departments in several systems at their institution. On average, 2.4 areas of an institution are involved in the processes. 66.3% of respondents rated the cooperation between the institutions involved as ‘very good’ or ‘fairly good’. The reliability of the recording process varies depending on the source of funds, with the use of funds managed by a central service organisation being rated as the most reliable. 80.2% rated the contribution of recording publication costs to shaping the open access transformation as ‘very important’ or ‘fairly important’. However, the data collected is not the basis for strategic decisions at all institutions. The implementation of an information budget by 2025 is considered unlikely at most institutions."
  },
  {
    "objectID": "events/oat24_20240910.html",
    "href": "events/oat24_20240910.html",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "",
    "text": "Date: 10.09.2024\nTime: 13:30–15:00 PM CEST\nRoom: Room 149\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/oat24_20240910.html#dates",
    "href": "events/oat24_20240910.html#dates",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "",
    "text": "Date: 10.09.2024\nTime: 13:30–15:00 PM CEST\nRoom: Room 149\nProgramme on the organiser’s website"
  },
  {
    "objectID": "events/oat24_20240910.html#description",
    "href": "events/oat24_20240910.html#description",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "Description",
    "text": "Description\nAgainst the background of the definition of explicit targets for the volume of open access publications by the Federal Ministry of Education and Research, some federal states and various other stakeholders, open access reporting is becoming increasingly important. At the same time, circumstances such as the complex data situation make it difficult to implement procedures across the board, and it is becoming clear that the recording of publication volumes should be supplemented by the consideration of further indicators in order to do better justice to the different types of universities and their disciplinary orientation.\nThis interactive workshop is therefore aimed at staff at scientific institutions who are interested in carrying out open access reporting. The workshop will examine and discuss different approaches to open access reporting and provide practical examples of the concrete reporting procedure. The workshop will open with short practical reports on open access reporting at state level based on qualitative and quantitative approaches by the Open Access Office Berlin and the Brandenburg Networking and Competence Centre. Participants will then be given an insight into the use of the Open Access Monitor 1 for reporting the publication volume of their institution and supplementary information on strategies and services of scientific institutions based on the oa.atlas 2 using their own questions and analysis scenarios. Using prepared impulses, participants discuss the opportunities and challenges of the reporting approaches presented in small groups before the results are briefly presented in plenary. After completing the workshop, participants will be familiar with various approaches to open access reporting and will be able to use the Open Access Monitor and the oa.atlas to prepare a report on their open access activities and the publication output of their institution.\nA maximum of 20 people (excluding the organisers) can take part in the workshop. Participants must bring their own laptop."
  },
  {
    "objectID": "events/oat24_20240910.html#footnotes",
    "href": "events/oat24_20240910.html#footnotes",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nopen-access-monitor.de↩︎\nopen-access.network/services/oaatlas↩︎"
  },
  {
    "objectID": "events/dini24_20240919.html",
    "href": "events/dini24_20240919.html",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "",
    "text": "Date: 19.09.2024\nTime: 11:15 AM to 12:15 PM CEST\nProgramme on the organiser’s website\nWorkshop Report"
  },
  {
    "objectID": "events/dini24_20240919.html#dates",
    "href": "events/dini24_20240919.html#dates",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "",
    "text": "Date: 19.09.2024\nTime: 11:15 AM to 12:15 PM CEST\nProgramme on the organiser’s website\nWorkshop Report"
  },
  {
    "objectID": "events/dini24_20240919.html#description",
    "href": "events/dini24_20240919.html#description",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "Description",
    "text": "Description\nBoth the Open Access strategy of the Federal Ministry of Education and Research (BMBF) and the European Commission’s recommendations on OA to the EU member states call on scientific institutions to increase the transparency of contractual agreements with publishers. The Alliance of German Science Organisations also addresses this issue. In practice, however, with a few exceptions (e.g. the disclosure of DEAL contracts), this demand has not been implemented. While the OpenAPC initiative has created an internationally recognised approach to the disclosure of funds in the area of publication fees, there is still no such initiative for subscription costs, for example. Against this background, the DFG project Transform2Open is endeavouring to create a national transparency initiative that addresses subscription, transformation and OA contracts. Of particular interest are the handling of non-disclosure agreements and current obstacles to transparency endeavours. Practical procedures for disclosing costs are also an important topic. Efforts to open up research information, e.g. as part of the ‘Barcelona Declaration on Open Research Information’ initiative, are also creating new opportunities to pool data on publications and their costs. Under the conference motto ‘Shared infrastructures for open science’ of the 25th annual conference of the German Initiative for Networked Information (DINI) on 19 September 2024 in Potsdam, a World Café workshop was held to discuss which aspects and institutions should initially be focused on for a prototype implementation of a transparency initiative. Implementation challenges were jointly identified in order to prepare for practical implementation. The workshop was jointly organised by the DFG projects Transform2Open and OA Datenpraxis. OA Datenpraxis supports the development of structures for the open access transformation at national level. Close cooperation with stakeholders from the DEAL project, OpenAPC, openCost and the OA Monitor exists or will be further expanded."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "The content of the OA Datenpraxis website is made available under the Creative Commons Attribution license. The following is a human-readable summary of (and not a substitute for) the full legal text of the CC BY 4.0 license.\nYou are free:\n\nto Share—copy and redistribute the material in any medium or format\nto Adapt—remix, transform, and build upon the material\n\nfor any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\n\nAttribution—You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions—You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. With the understanding that:\n\nNotices:\n\nYou do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\nNo warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dashboards.html",
    "href": "dashboards.html",
    "title": "Open Access Dashboard Collection",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "OpenAPC.html",
    "href": "OpenAPC.html",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "",
    "text": "OpenAPC is an initiative that aims to collect information on payments for open access publications (Pieper and Broschinski 2018). The project is located at Bielefeld University Library and started ingesting data from research organizations in 2014. Although the project initially started with a focus on Germany, institutions from more than 20 countries share payment information via OpenAPC as of 2025.\nIf research organizations are pursuing a complete transition away from the subscription model and toward open access, it is important to understand the financial dimension. However, data on open access costs are difficult to obtain. Prices listed on publisher websites can be useful to understand what publishers charge for open access publications. There are lists that collect this information and enable comprehensive analyses across multiple publishers (Butler et al. 2024). In contrast to these price lists, OpenAPC collects information about payments research organizations made. The amounts paid can differ from prices listed on publisher websites, for example if the organization has signed an agreement with the publisher, or if a publisher grants a discount.\nThe OpenAPC dataset shows how much money was spent to publish open access. The initiators imagine that the dataset “[can] be reused to make cash flows between research institutions and publishers more transparent.” (OpenAPC n.d.)\nParticipating in OpenAPC is voluntary. Not all institutions collect data about these payments or pass the data on to OpenAPC."
  },
  {
    "objectID": "OpenAPC.html#the-github-repository",
    "href": "OpenAPC.html#the-github-repository",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "The GitHub repository",
    "text": "The GitHub repository\nThe project is organized in a GitHub repository. You can find and download csv-files with payment information for individual institutions in the folder data."
  },
  {
    "objectID": "OpenAPC.html#the-olap-server",
    "href": "OpenAPC.html#the-olap-server",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "The OLAP server",
    "text": "The OLAP server\nThe OLAP server allows programmatic access to and retrieval of OpenAPC data."
  },
  {
    "objectID": "OpenAPC.html#the-dashboard",
    "href": "OpenAPC.html#the-dashboard",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "The Dashboard",
    "text": "The Dashboard\nOn the dashboard, you are able to filter the dataset, see a treemap visualization and download data."
  },
  {
    "objectID": "OpenAPC.html#loading-packages",
    "href": "OpenAPC.html#loading-packages",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "loading packages",
    "text": "loading packages\nWe will load the dplyr (Wickham et al. 2023) and tidyr (Wickham, Vaughan, and Girlich 2024) packages that provide a lot of additional functionalities for data wrangling, and ggplot2 (Wickham 2016) for data visualization. All three packages are part of the tidyverse package (Wickham et al. 2019).\n\n# Installation of packages if not already installed with\n# install.packages(c(\"dplyr\",\"tidyr\",\"ggplot2\"))\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "OpenAPC.html#loading-data",
    "href": "OpenAPC.html#loading-data",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "loading data",
    "text": "loading data\nWe will load the csv file downloaded from the OpenAPC dashboard and store it in the object df.\n\ndf &lt;- read.csv(\"facts.csv\")"
  },
  {
    "objectID": "OpenAPC.html#structure-of-the-dataset",
    "href": "OpenAPC.html#structure-of-the-dataset",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "structure of the dataset",
    "text": "structure of the dataset\nTo get an overview of the structure of our data frame, especially the number of rows (observations) and columns (variables), the individual column names and the data types they contain, we will use the glimpse function from the dplyr package.\n\nglimpse(df)\n\nRows: 4,331\nColumns: 10\n$ X__fact_key__      &lt;chr&gt; \"Charité - Universitätsmedizin Berlin\", \"Charité - …\n$ institution        &lt;chr&gt; \"Charité - Universitätsmedizin Berlin\", \"Charité - …\n$ period             &lt;int&gt; 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 201…\n$ publisher          &lt;chr&gt; \"Wiley-Blackwell\", \"Wiley-Blackwell\", \"Wiley-Blackw…\n$ journal_full_title &lt;chr&gt; \"International Journal of Gynecology & Obstetrics\",…\n$ issn               &lt;chr&gt; \"0020-7292\", \"0909-752X\", \"1552-4825\", \"0906-6705\",…\n$ doi                &lt;chr&gt; \"10.1002/ijgo.13099\", \"10.1111/srt.12800\", \"10.1002…\n$ is_hybrid          &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ country            &lt;chr&gt; \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"D…\n$ euro               &lt;dbl&gt; 4331.07, 4331.07, 4331.07, 4331.07, 4331.07, 4331.0…\n\n\nThe output shows that our data frame contains a total of 4,331 rows (observations) and 10 columns. Each row in the data frame corresponds to one APC payment. The output also shows that most of the column values are of data type character (chr), the period column values are of type integer (int), the is_hybrid column values are of type logical (lgl) and the euro column values are of type double-precision floating-point (dbl) - a format for decimal numbers. The output also indicates the first values of every column on the right hand side.\nTo look at the first 10 rows of our data frame we are using the head function.\n\nhead(df, 10)\n\n                          X__fact_key__                          institution\n1  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n2  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n3  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n4  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n5  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n6  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n7  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n8  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n9  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n10 Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n   period       publisher\n1    2019 Wiley-Blackwell\n2    2019 Wiley-Blackwell\n3    2019 Wiley-Blackwell\n4    2019 Wiley-Blackwell\n5    2019 Wiley-Blackwell\n6    2019 Wiley-Blackwell\n7    2019 Wiley-Blackwell\n8    2019 Wiley-Blackwell\n9    2019 Wiley-Blackwell\n10   2019 Wiley-Blackwell\n                                         journal_full_title      issn\n1          International Journal of Gynecology & Obstetrics 0020-7292\n2                              Skin Research and Technology 0909-752X\n3               American Journal of Medical Genetics Part A 1552-4825\n4                                  Experimental Dermatology 0906-6705\n5                              Journal of Internal Medicine 0954-6820\n6                                                Immunology 0019-2805\n7  JDDG Journal der Deutschen Dermatologischen Gesellschaft 1610-0379\n8                                                   Allergy 0105-4538\n9   Journal of Tissue Engineering and Regenerative Medicine 1932-6254\n10            Alcoholism Clinical and Experimental Research 0145-6008\n                    doi is_hybrid country    euro\n1    10.1002/ijgo.13099      TRUE     DEU 4331.07\n2     10.1111/srt.12800      TRUE     DEU 4331.07\n3  10.1002/ajmg.a.61419      TRUE     DEU 4331.07\n4     10.1111/exd.14007      TRUE     DEU 4331.07\n5    10.1111/joim.12985      TRUE     DEU 4331.07\n6     10.1111/imm.13138      TRUE     DEU 4331.07\n7     10.1111/ddg.14013      TRUE     DEU 4331.07\n8     10.1111/all.14015      TRUE     DEU 4331.07\n9     10.1002/term.2948      TRUE     DEU 4331.07\n10   10.1111/acer.14211      TRUE     DEU 4331.07\n\n\nThe first argument within the head function is our data frame df and the second argument is the number of rows we want to have returned. Each row within our data frame corresponds to an article."
  },
  {
    "objectID": "OpenAPC.html#analyzing-and-visualizing-open-access-payments",
    "href": "OpenAPC.html#analyzing-and-visualizing-open-access-payments",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "Analyzing and visualizing open access payments",
    "text": "Analyzing and visualizing open access payments\nIn the following sections, we will analyze the data to address our questions and generate visualizations.\nHow much did the institution spend on open access publications in total?\nTo determine total open access spending of the research organization, we are using the sum function and apply it to the colum euro. The OpenAPC schema states that this column contains “[t]he APC amount that was paid in EURO. Includes VAT and any discounts”.\n\nsum(df$euro)\n\n[1] 8669107\n\n\nWithout context, this number does not say much. Applying the min and max functions to the column period (“Year of APC payment (YYYY)”), we can see that this sum was accrued over a period of 6 years, from 2018 to 2023.\n\nmin(df$period)\n\n[1] 2018\n\nmax(df$period)\n\n[1] 2023\n\n\nBecause it takes research organizations time to collect and process data on APC payments and submit it to OpenAPC, there is usually a delay in reporting. In this example, data for 2024 is not yet available.\nHow are payments distributed across journals?\nThe R package dplyr provides a lot of functionality for data wrangling. We can’t go into much detail here, but we will demonstrate how to use some of the most useful functions.\nOne of them is the group_by function. Here, we use it to group the dataset by the column journal_full_title. This will allow us to generate aggregate statistics for articles published within a journal. We then use the pipe operator |&gt;, which takes output from one function as input for the next function. The input is passed to the summarise function, where we calculate aggregate statistics. For each journal in the dataset, we calculate the total number of articles published (n_articles), the total of APCs paid (sum_apc), the average APC paid per article (avg_apc), and the standard deviation (sd_apc). The last two statistics are rounded to two decimal places. To get a better overview of the data, we then use arrange to sort the result by the total number of articles.\n\ndf |&gt;\n  group_by(journal_full_title) |&gt;\n  summarise(\n    n_articles = n(),\n    sum_apc = sum(euro),\n    avg_apc = round(sum_apc / n_articles, 2),\n    sd_apc = round(sd(euro), 2)\n  ) |&gt;\n  arrange(desc(n_articles))\n\n# A tibble: 923 × 5\n   journal_full_title                          n_articles sum_apc avg_apc sd_apc\n   &lt;chr&gt;                                            &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Scientific Reports                                 232 433492.   1868.   141.\n 2 PLOS ONE                                           134 223456.   1668.   210.\n 3 Frontiers in Immunology                            130 276129.   2124.   516.\n 4 International Journal of Molecular Sciences        124 222282.   1793.   331.\n 5 Journal of Clinical Medicine                       120 212463.   1771.   502.\n 6 Frontiers in Neurology                              70 144595.   2066.   558.\n 7 Cancers                                             66 118423.   1794.   557.\n 8 Allergy                                             61 168277.   2759.   623.\n 9 Frontiers in Psychiatry                             60 128626.   2144.   638.\n10 Frontiers in Physiology                             43  91332    2124    474.\n# ℹ 913 more rows\n\n\nThe results show that Charité paid APCs for 923 journals, as indicated by the number of rows. Most APC payments were made to the journals Scientific Reports, PLOS ONE, and Frontiers in Immunology. The column sd_apc tells us that for some journals, there is a considerable variance in APC payments.\nWe can explore this variance further by visualizing the distribution of APC payments. For this, we will use the packages dplyr and ggplot2. First, we filter the data to focus on the three journals with the most APC payments. We then pass this output to the ggplot function. We assign the column euro to the x axis and the column journal_full_title to the y axis. Next, we define the type of plot we want - here, we choose a box plot to visualize a distribution. Finally, we choose the theme theme_minimal for a simple layout.\n\ndf |&gt;\n  filter(journal_full_title %in% c(\"Scientific Reports\", \"PLOS ONE\", \"Frontiers in Immunology\")) |&gt;\n  ggplot(aes(x = euro, y = journal_full_title)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\nThese box plots show clear differences in the distribution of APC payments. The three journals differ in the median amount of APCs paid - the median is the middle point in a distribution and is visualized by the vertical line in the box plot. We also see that the range of APC payments is highest for Frontiers in Immunology: there are outliers at the bottom and top end of the distribution, as indicated by the dots.\nHow do payments evolve over the years?\nWe can combine dplyr and ggplot2 to visualize the development of APC payments over time. We will also consider open access types (gold / hybrid).\nFirst, we group the data by period (“Year of APC payment (YYYY)”) and is_hybrid (“Determines if the article has been published in a hybrid journal (TRUE) or in fully/Gold OA journal (FALSE)”). Just like above, we will generate the aggregate statistic n_articles. In the ggplot function, we assign the column period to the x axis, n_articles to the y axis, and is_hybrid to fill - this means that different colours will be assigned to the open access types. We choose the graph type geom_col, a simple bar chart.\n\ndf |&gt;\n  group_by(period, is_hybrid) |&gt;\n  summarise(n_articles = n()) |&gt;\n  ggplot(aes(x = period, y = n_articles, fill = is_hybrid)) +\n  geom_col() +\n  theme_minimal()\n\n\n\n\n\n\n\nThe plot tells us that the number of APC payments has increased between 2018 and 2021 and has dropped off since. We can also see that APC payments for publications in hybrid open access journals have increased considerably between 2019 and 2020. This is likely the result of transformative agreements between German research organizations and publishers."
  },
  {
    "objectID": "OpenAPC.html#aggregate-statistics-for-publishers",
    "href": "OpenAPC.html#aggregate-statistics-for-publishers",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "1. Aggregate statistics for publishers",
    "text": "1. Aggregate statistics for publishers\nAbove, we analyzed APC payments by journal. Here is a copy of that code block. See if you can adapt it to give you aggregate statistics for publishers instead.\n\n\n Interactive editor\n Solution\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhich publishers received the highest amount of APC payments from Charité? Do you notice any interesting patterns?"
  },
  {
    "objectID": "OpenAPC.html#visuzlization-of-apc-distribution-by-publisher",
    "href": "OpenAPC.html#visuzlization-of-apc-distribution-by-publisher",
    "title": "Open Access Cost Monitoring with OpenAPC",
    "section": "2. Visuzlization of APC distribution by publisher",
    "text": "2. Visuzlization of APC distribution by publisher\nNow, see if you can adapt the code above to show you the distribution of APC payments by publisher.\n\n\n Interactive editor\n Solution\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "rankings.html",
    "href": "rankings.html",
    "title": "Open Access in institutional Rankings",
    "section": "",
    "text": "Institutional or university rankings attract a great deal of attention in science policy and the public sphere because they enable scientific institutions to be easily compared with one another on a global level. They serve various interest groups, such as political decision-makers, university managers and prospective students, as a tool for strategic decision-making, illustrating institutional excellence or choosing a place to study (Waltman et al., 2012). The methodologies on which the rankings are based are repeatedly criticised, for example because of their tendency to summarise multiple dimensions of the performance spectrum of scientific institutions into a single, often intransparent score (Diprose et al., 2023; Piro & Sivertsen, 2016; van Raan, 2005). This approach not only makes it difficult to interpret the rankings, but also fails to take sufficient account of the different tasks and priorities of the institutions (Huang et al., 2020; Waltman et al., 2012).\nFive institutional rankings with Open Access as a comparative dimension could be identified: the Leiden Ranking 2024 (LR), the Leiden Ranking Open Edition 2024 (LROE), the SCImago Institutions Ranking 2024 (SIR), the Quacquarelli Symonds World University Rankings: Sustainability 2025 (QS), and the COKI OA Dashboard 2025 (COKI). All five rankings include one or more Open Access indicators and are globally oriented in terms of geographical coverage.\nThis page provides an overview of the characteristics of the five rankings, as well as an investigation into the extent to which the results of the rankings are comparable. This includes, among other things, a comparison of the data sources and Open Access indicators used by the rankings, as well as a review of the extent to which institutions can participate in the data collection by the ranking providers. The focus is particularly on the Open Access dimension."
  },
  {
    "objectID": "rankings.html#footnotes",
    "href": "rankings.html#footnotes",
    "title": "Open Access in institutional Rankings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nInformation on the availability of data, including a link to download the version of the data used (if available), is provided for all rankings in the respective “Ranking Details” section.↩︎\nFor example, in the SCImago Institutions Ranking, the Deutsche Krebsforschungszentrum is listed in the national language, while in ROR, the English name German Cancer Research Center is used as the primary designation.↩︎\nClicking on the figures enlarges them for better viewing.↩︎\nFormally, Moed (2016) defines preference as: \\(P= \\dfrac{\\bigg(\\dfrac{n[i, j]}{\\sum_i n[i, j]}\\bigg)}{\\bigg(\\dfrac{\\sum_jn[i, j]}{\\sum_i\\sum_jn[i, j]}\\bigg)}\\), where \\(n[i, j]\\) represents the number of institutions from country \\(i\\) in ranking system \\(j\\), \\(\\sum_in[i, j]\\) is the sum of all \\(n[i, j]\\) across all \\(i\\) (countries), \\(\\sum_jn[i, j]\\) is the sum of all \\(n[i, j]\\) across all \\(j\\) (ranking systems), and \\(\\sum_i\\sum_jn[i, j]\\) is the sum of all \\(n[i, j]\\) across all \\(i\\) (countries) and all \\(j\\) (ranking systems).↩︎"
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "Legal Notice",
    "section": "",
    "text": "Berlin School of Library and Information Science, Humboldt-Universität zu Berlin\nDorotheenstr. 26\n10117 Berlin\nGermany\nKontakt\nProf. Dr. Heinz Pampel\nE-Mail: heinz.pampel@hu-berlin.de\nPhone: (+49 30) 2093 70977\n\n\n\n Back to top"
  },
  {
    "objectID": "aps/AP6.html#description",
    "href": "aps/AP6.html#description",
    "title": "WP 6 Trainings",
    "section": "Description",
    "text": "Description\nThe Carpentries (consisting of Data, Library and Software Carpentry) are a method of introducing basic data competences. The main focus is on the joint learning of IT-supported procedures for solving practical problems. In Germany, both library associations and academic institutions support the Carpentries community through membership. For example, the SUB Göttingen has been a member since 2019 and trains up to five instructors annually at the Göttingen campus and regularly organises Carpentries workshops, which are primarily aimed at young researchers and librarians. The aim of the AP is to design, test and iteratively develop training courses with a specific focus on data practice to shape the OA transformation as part of Library Carpentry. The target group includes professionals in the field of OA transformation and research administration. Not all data analysis aspects can be covered within a Carpentry training course. Rather, the aim is to introduce open and science-oriented tools and procedures and to test their application (Wilson et al., 2017). The tasks of the WP are based on the life cycle of the Carpentries Lessons and start in the second year of the project."
  },
  {
    "objectID": "aps/AP2.html#description",
    "href": "aps/AP2.html#description",
    "title": "WP 2 Publisher Agreements",
    "section": "Description",
    "text": "Description\nOA transformation agreements are heterogeneous in terms of open metadata despite standardisation initiatives such as ESAC (Borrego et al., 2021; Jahn et al., 2022; Marques et al., 2019). At the same time, publishers offer varying degrees of metadata and research services in addition to the OA provision of articles and centralised accounting. The aim of the WP is to analyse publisher agreements relating to open metadata and data-analytical research services and to identify best practices. This is intended to promote competition between publishers."
  },
  {
    "objectID": "aps/AP4.html#description",
    "href": "aps/AP4.html#description",
    "title": "WP 4 Open-Access-Reporting",
    "section": "Description",
    "text": "Description\nThe digital strategy of the Federal Ministry of Education and Research (BMBF) states: “By 2025, 70 per cent of all new scientific publications in Germany will be published exclusively or additionally via open access.” (Bundesministerium für Bildung und Forschung, 2019, p. 37). In addition to this national OA target, individual federal states have defined specific OA targets. In the “2019 Monitoring Report” of the Joint Science Conference’s (GWK) Pact for Research and Innovation (PFI), the federal and state governments emphasise the need to establish “consistent and comparable surveys on open access publications” (Gemeinsame Wissenschaftskonferenz, 2019, p. 16). In a discussion paper published in 2022 by the Working Group on the Scientific Publication System in the Alliance’s priority initiative “Digital Information”, an initial proposal for a common set of indicators on OA for Germany is formulated (Deinzer et al., 2022). The problem with this proposal is that it has not yet been discussed beyond the working group.\nWP 4 builds on this work - in which an applicant was involved as head of the responsible task group of the Scientific Publication System WG - and organises a dialogue to further develop this proposal on the basis of the discussion paper. The aim is to develop a national standard for the definition of OA for reporting and the associated data collection practice."
  },
  {
    "objectID": "aps/AP1.html#description",
    "href": "aps/AP1.html#description",
    "title": "WP 1 Institutional Level",
    "section": "Description",
    "text": "Description\nThe basis for the overall project is an inventory that identifies and documents the topic, the actors and the interplay of aspects of data analyses for shaping the OA transformation. For this purpose, a target group-specific view of professionals who deal with the OA transformation in operational and strategic areas of scientific institutions on the basis of publication and cost data is taken. The focus is on administrative and library staff at universities and non-university institutions. These include professionals in the areas of digital publishing, OA, acquisition and collection development, research information and research funding.\nBased on a stakeholder analysis (T1.1), the need for information, the handling of data sources and the interdependence of data analyses in the context of OA transformation at academic institutions will be surveyed (T1.2). The potential of the open science monitoring systems currently being developed will also be analysed. The resulting inventory (T1.3), which looks at the specific practices in dealing with data on OA and future requirements of those involved, will create the basis for recommendations on the topic (WP 5)."
  },
  {
    "objectID": "partners.html",
    "href": "partners.html",
    "title": "Project Partner",
    "section": "",
    "text": "The Chair of Information Management at the Berlin School of Library and Information Science at HU is investigating the role of digital research and information infrastructures in science in the context of the digital transformation. The focus is on information infrastructures that enable the collection, indexing, accessibility and re-use of information objects in the sense of Open Science. In research, teaching and transfer, processes of digital science communication and associated practices, standards and policies are analysed. Research focuses on the topic of Open Access and related developments in digital scholarly communication.\n\n\nHeinz Pampel https://orcid.org/0000-0003-3334-2771\nDorothea Strecker https://orcid.org/0000-0002-9754-3807"
  },
  {
    "objectID": "partners.html#humboldt-universität-zu-berlin-berlin-school-of-library-and-information-science",
    "href": "partners.html#humboldt-universität-zu-berlin-berlin-school-of-library-and-information-science",
    "title": "Project Partner",
    "section": "",
    "text": "The Chair of Information Management at the Berlin School of Library and Information Science at HU is investigating the role of digital research and information infrastructures in science in the context of the digital transformation. The focus is on information infrastructures that enable the collection, indexing, accessibility and re-use of information objects in the sense of Open Science. In research, teaching and transfer, processes of digital science communication and associated practices, standards and policies are analysed. Research focuses on the topic of Open Access and related developments in digital scholarly communication.\n\n\nHeinz Pampel https://orcid.org/0000-0003-3334-2771\nDorothea Strecker https://orcid.org/0000-0002-9754-3807"
  },
  {
    "objectID": "partners.html#helmholtz-open-science-office",
    "href": "partners.html#helmholtz-open-science-office",
    "title": "Project Partner",
    "section": "Helmholtz Open Science Office",
    "text": "Helmholtz Open Science Office\nThe Helmholtz Association supports OA in accordance with the “Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities”. With the Helmholtz Open Science Office (OS Office), an infrastructure has been established that promotes the cultural change towards Open Science at Helmholtz. The OS Office sees itself as a service provider and cross-centre partner for all stakeholders involved in this process, supporting the Helmholtz Association in shaping the cultural change towards Open Science at national and international level. With this objective in mind, the OS Office is involved in a large number of open science initiatives and projects, such as in relevant working groups of the Alliance of Science Organisations’ priority initiative “Digital Information”, on the board and in various committees of the DINI and the RDA DE association and as part of various third-party funded projects.\n\nTeam\nMathijs Vleugel https://orcid.org/0000-0003-2988-2628\nLea Maria Ferguson https://orcid.org/0000-0002-7060-3670\nJohannes Schneider https://orcid.org/0009-0004-6510-166X"
  },
  {
    "objectID": "partners.html#göttingen-state-and-university-library",
    "href": "partners.html#göttingen-state-and-university-library",
    "title": "Project Partner",
    "section": "Göttingen State and University Library",
    "text": "Göttingen State and University Library\nThe Göttingen State and University Library (SUB Göttingen) is one of Germany’s leading libraries with its diverse range of tasks, which it fulfils at local, regional, national and international level. As an internationally recognised competence centre for the digital library, it provides new services for research. Its tasks include securing the supra-regional supply of literature, as in the DFG-funded programme “Specialised Information Services for Science”, preserving and making accessible scientific results and the cultural-historical heritage, as well as its commitment to being a research and development partner for a future-proof research and information infrastructure in Germany and internationally.\n\nTeam\nNajko Jahn https://orcid.org/0000-0001-5105-1463\nBirgit Schmidt https://orcid.org/0000-0001-8036-5859\nSophia Dörner https://orcid.org/0000-0001-8747-3422"
  },
  {
    "objectID": "arbeitspakete.html",
    "href": "arbeitspakete.html",
    "title": "Work Packages",
    "section": "",
    "text": "WP 1 Institutional Level\nThe aim of WP 1 is to collect, analyse and document requirements for data analyses relating to the OA transformation from the institutional practice of scientific institutions. The results of WP 1 will be published in a report and formulated in recommendations.\n\n\nWP 2 Publisher Agreements\nThe aim of WP 2 is to analyse publishing contracts relating to open metadata and data analytics research services and to identify best practices. The result is an inventory of German transformation contracts and a recommendation for action.\n\n\nWP 3 Open Access in institutional Rankings\nThe aim of WP 3 is to critically accompany OA as an evaluation dimension of institutional rankings. To this end, interpretation and intervention aids for the management of scientific institutions will be developed on the basis of an inventory of institutional rankings. Secondly, data analysis aids will be developed and published to enable institutions and consortia to carry out benchmarking on the basis of data from university rankings.\n\n\nWP 4 Open-Access-Reporting\nThe aim of WP 4 is to contribute to the improvement of data quality and to promote the standardisation of data and reports on OA transformation. As a result of WP 4, the proposal for a standard of the Alliance of Science Organisations for OA reporting will be further developed as part of an assessment process.\n\n\nWP 5 Synopsis\nThe aim of WP 5 is to summarise the results from WPs 1, 2, 3 and 4 in a strategic recommendation on data practices for shaping the OA transformation.\n\n\nWP 6 Trainings\nThe aim of WP 6 is to develop and test open training materials on the use of open data sources and tools in the form of a Carpentry module in a participatory manner. The work planning is based on the life cycle of the Carpentry lessons and includes the call for teamwork, creation of the course materials, testing and revision phase.\n\n\nWP 7 Tools\nThe aim of the WP is to set up and operate a digital toolbox that provides information on tools for collecting, analysing and visualising data relating to OA transformation.\n\n\nWP 8 Networks\nThe aim of the WP is to initiate networks on specific issues relating to data work on OA transformation. At the heart of this is the dialogue on the topics of: Reporting, publishing data, bibliometrics and mentoring in the context of OA transformation. The project organises digital workshops for the networks and provides an organisational structure.\n\n\n\n\n Back to top"
  }
]