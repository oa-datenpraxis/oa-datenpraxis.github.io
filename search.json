[
  {
    "objectID": "dashboards_schema.html",
    "href": "dashboards_schema.html",
    "title": "Metadatenschema",
    "section": "",
    "text": "ID\nProperty\nDefinition\nOcc\nValues\nExample\n\n\n\n\n1\nName\nName given to the dashboard by its authors, from (in descending priority): provided citation form, name given in associated publication, self-description on the website (header, ‘about’ page, self-referring term throughout the website), browser tab name; year is removed from dashboard name if there are versions for multiple years; instances of dashboard collections are named after the scheme ‘[Name of dashboard collection]: [Name of organization]’\n1\n\nFrench Open Science Monitor, CWTS Leiden Ranking, OpenAIRE Monitor Dashboard: Universität Göttingen\n\n\n2\nURL\nURL to homepage of the dashboard; if listed dashboard is only one of other dashboard-unrelated services on a website, URL of the specific webpage\n1\n\nhttps://open.coki.ac/\n\n\n3\nTime period\nTime period in years from the year of earliest data presented in the dashboard to the year of latest data; note: this is not the year of publication in the dashboard - ‘year of latest data’ earlier than 2024 does not necessarily mean the dashboard is inactive; the Leiden Ranking 2024 e.g. refers to data from 2019–2022\n1-n\n[year of common era]–[year of common era]\n2018–2024\n\n\n4\nOperator\nName of operator responsible for running the dashboard; if that operator does not have an associated ROR, but there is an organization containing the operator that has a ROR, this organization is listed after the original operator, separated by comma; multiple direct operators are separated by semicolon.\n1-n\n\nCentre for Science and Technology Studies (CWTS), Leiden University\n\n\n4.1\nROR\nROR of the organization(s) listed under 4 if available, N/A if unavailable\n1-n\nROR ID as an operable URL, N/A\nhttps://ror.org/027bh9e22\n\n\n4.2\nOperator type\nType of organization running the dashboard, distinguishing two major types of research-related organizations, Research Performing and Funding Organizations (‘RPO’ and ‘RFO’ respectively), with ‘other’ for everything else\n1-n\nResearch performing organization (RPO), Research funding organization (RFO), other\nRPO\n\n\n5.1\nScope\nScope of the coverage of dashboard: international if data for more than one country, national if data for one country, institutional if data on one or more organizations but not country-wide\n1\ninternational, national, research institution\ninternational\n\n\n5.2\nCountries\nCountry code of the organization(s) whose data are represented in the dashboard, represented with country code value ‘Europe’ if more than 1 country but all from EU + Switzerland OR Norway OR UK value ‘global’ if more than 1 country and more than 3 countries outside of ‘Europe’\n1-n\nControlled vocabulary: 3-letter ISO 3166-1 alpha-3 country code; additionally: ‘Europe’, ‘global’\nDEU\n\n\n6\nData type\nType of data that the dashboard shows ‘publications’ for data on textual publications such as e.g. journal articles ‘data’ for research data ‘software’ for research software ‘infrastructures’ for data on e.g. repositories ‘other’ for data that does not fall under any of the other categories\n1-n\npublications, data, software, infrustructures, other\npublications\n\n\n7\nDashboard license\nCopyright license of the software used to create the dashboard; if the dashboard provides a generic license for its website without specifically mentioning the software or its dataset, this license is instead entered here\n1-n\ncontrolled vocabulary: SPDX License List entries, N/A\nMIT, Apache-2.0\n\n\n8\nData license\nCopyright license under which the data of the dashboard is published\n1-n\ncontrolled vocabulary: SPDX License List entries, N/A\nCC-BY-4,0, CC0-1.0\n\n\n9\nData source\nAvailability of the data source the dashboard is based on: ‘open’ if data comes from an open source such as e.g. OpenAlex, ‘proprietary’ if not, both values if dashboard uses data sources of both types\n1-n\nopen, restricted, N/A\nopen\n\n\n10\nCollection\nNames the dashboard collection the dashboard is part of if applicable; ‘N/A’ otherwise\n1\nstring of the dashboard collection name, N/A\nOpenAIRE Monitor Dashboard, CHORUS dashboard\n\n\n11\nDocumentation\nFree text field in which relevant links and comments are gathered; these can include: links to the specific part of the website where the various licenses are mentioned, DOIs to accompanying publications about the dashboard and other comments\n1-n\nstring of comment, N/A\nData source: https://bibliotecnica.upc.edu/en/observatori#metodologia\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "OpenAlex.html",
    "href": "OpenAlex.html",
    "title": "OpenAlex",
    "section": "",
    "text": "Note\n\n\n\nDieses Notebook wird nur in English angeboten"
  },
  {
    "objectID": "OpenAlex.html#the-openalex-web-user-interface",
    "href": "OpenAlex.html#the-openalex-web-user-interface",
    "title": "OpenAlex",
    "section": "The OpenAlex web user interface",
    "text": "The OpenAlex web user interface\nIn the web user interface you are able to query the database via a search bar, apply filters and export the results in csv, ris or txt format."
  },
  {
    "objectID": "OpenAlex.html#the-openalex-api",
    "href": "OpenAlex.html#the-openalex-api",
    "title": "OpenAlex",
    "section": "The OpenAlex API",
    "text": "The OpenAlex API\nThe OpenAlex REST API allows programmatic access to and retrieval of OpenAlex data. The API has a limit of 100,000 calls per user per day. Though no authentication is required it is advised to add your email address to all API requests in order to get into the polite pool."
  },
  {
    "objectID": "OpenAlex.html#the-openalex-data-snapshot",
    "href": "OpenAlex.html#the-openalex-data-snapshot",
    "title": "OpenAlex",
    "section": "The OpenAlex data snapshot",
    "text": "The OpenAlex data snapshot\nOpenAlex additionally offers a data snapshot with a copy of the complete database for download, which a user can then load into their own data warehouse or relational database. The snapshot gets updated monthly."
  },
  {
    "objectID": "OpenAlex.html#loading-packages",
    "href": "OpenAlex.html#loading-packages",
    "title": "OpenAlex",
    "section": "Loading packages",
    "text": "Loading packages\nWe will load the openalexR package (Aria et al. 2024) that allows us to query the OpenAlex API from within our notebook and the tidyverse package (Wickham et al. 2019) that provides a lot of additional functionalities for data wrangling and visualization.\n\n# Installation of packages if not already installed with\n# install.packages(c(\"openalexR\",\"tidyverse\"))\nlibrary(openalexR)\nlibrary(tidyverse)"
  },
  {
    "objectID": "OpenAlex.html#loading-data",
    "href": "OpenAlex.html#loading-data",
    "title": "OpenAlex",
    "section": "Loading data",
    "text": "Loading data\nWe will use the oa_fetch function from the openalexR package to query the OpenAlex API and store the returned tibble (a data frame that works well with the tidyverse) in the object df.\n\ndf &lt;- oa_fetch(\n  entity = \"works\",\n  institutions.ror = \"01y9bpm73\", # change the ROR id if you want to analyse the performance of another institution\n  type = \"article\",\n  is_paratext = FALSE,\n  is_retracted = FALSE,\n  from_publication_date = \"2020-01-01\",\n  to_publication_date = \"2024-12-31\",\n  options = list(select = c(\n    \"id\", \"doi\", \"title\", \"publication_year\",\n    \"primary_location\", \"open_access\", \"apc_list\", \"apc_paid\"\n  )),\n  output = \"tibble\",\n  paging = \"cursor\",\n  abstract = FALSE,\n  mailto = \"example@domain.com\" # add your email address here to get into the polite pool\n)"
  },
  {
    "objectID": "OpenAlex.html#structure-of-the-dataset",
    "href": "OpenAlex.html#structure-of-the-dataset",
    "title": "OpenAlex",
    "section": "Structure of the dataset",
    "text": "Structure of the dataset\nTo get an overview of the structure of our data frame, especially the number of rows (observations) and columns (variables), the individual column names and the data types they contain, we will use the glimpse function from the dplyr package, which is part of the tidyverse.\n\nglimpse(df)\n\nRows: 15,952\nColumns: 19\n$ id                          &lt;chr&gt; \"https://openalex.org/W3009912996\", \"https…\n$ title                       &lt;chr&gt; \"SARS-CoV-2 Cell Entry Depends on ACE2 and…\n$ doi                         &lt;chr&gt; \"https://doi.org/10.1016/j.cell.2020.02.05…\n$ publication_year            &lt;int&gt; 2020, 2021, 2020, 2020, 2020, 2020, 2020, …\n$ is_oa                       &lt;lgl&gt; TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n$ is_oa_anywhere              &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE,…\n$ oa_status                   &lt;chr&gt; \"bronze\", \"green\", \"bronze\", \"hybrid\", \"hy…\n$ oa_url                      &lt;chr&gt; \"https://www.cell.com/article/S00928674203…\n$ any_repository_has_fulltext &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE…\n$ source_display_name         &lt;chr&gt; \"Cell\", \"Diabetes Research and Clinical Pr…\n$ source_id                   &lt;chr&gt; \"https://openalex.org/S110447773\", \"https:…\n$ issn_l                      &lt;chr&gt; \"0092-8674\", \"0168-8227\", \"1097-2765\", \"00…\n$ host_organization           &lt;chr&gt; \"https://openalex.org/P4310315673\", \"https…\n$ host_organization_name      &lt;chr&gt; \"Cell Press\", \"Elsevier BV\", \"Elsevier BV\"…\n$ landing_page_url            &lt;chr&gt; \"https://doi.org/10.1016/j.cell.2020.02.05…\n$ pdf_url                     &lt;chr&gt; \"https://www.cell.com/article/S00928674203…\n$ license                     &lt;chr&gt; \"other-oa\", NA, \"other-oa\", \"cc-by\", \"cc-b…\n$ version                     &lt;chr&gt; \"publishedVersion\", NA, \"publishedVersion\"…\n$ apc                         &lt;list&gt; [&lt;data.frame[2 x 5]&gt;], [&lt;data.frame[2 x 5…\n\n\nThe output shows that our data frame contains a total of 15,952 rows (observations) and 19 columns. Furthermore, it shows that most of the column values are of data type character (chr), the publication year column values are of type integer (int), some of the open access column values are of type logical (lgl) and the apc column values are of type list (list). The output also indicates the first values of every column on the right hand side.\nThe first values show us two important things:\n\nThere are at least some missing values within our data frame as is indicated by the NA in the license and version columns. NA is not a common string or numeric value, but a reserved word in R for the logical constant which contains a missing value indicator, i.e. R uses NA to indicate that the specific value is missing.\nThe apc column contains data frames as values. This means we can’t access the apc information directly. We will explore later in the notebook how to transform the column and access the apc information.\n\nTo look at the first 10 rows of our data frame we are using the head function.\n\nhead(df, 10)\n\n# A tibble: 10 × 19\n   id         title doi   publication_year is_oa is_oa_anywhere oa_status oa_url\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;            &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;          &lt;chr&gt;     &lt;chr&gt; \n 1 https://o… SARS… http…             2020 TRUE  TRUE           bronze    https…\n 2 https://o… IDF … http…             2021 FALSE TRUE           green     https…\n 3 https://o… A Mu… http…             2020 TRUE  TRUE           bronze    https…\n 4 https://o… Neur… http…             2020 TRUE  TRUE           hybrid    https…\n 5 https://o… COVI… http…             2020 TRUE  TRUE           hybrid    https…\n 6 https://o… Olfa… http…             2020 TRUE  TRUE           hybrid    https…\n 7 https://o… Mana… http…             2020 TRUE  FALSE          closed    https…\n 8 https://o… SARS… http…             2021 TRUE  TRUE           green     https…\n 9 https://o… Infe… http…             2020 TRUE  TRUE           hybrid    https…\n10 https://o… The … http…             2021 TRUE  TRUE           bronze    https…\n# ℹ 11 more variables: any_repository_has_fulltext &lt;lgl&gt;,\n#   source_display_name &lt;chr&gt;, source_id &lt;chr&gt;, issn_l &lt;chr&gt;,\n#   host_organization &lt;chr&gt;, host_organization_name &lt;chr&gt;,\n#   landing_page_url &lt;chr&gt;, pdf_url &lt;chr&gt;, license &lt;chr&gt;, version &lt;chr&gt;,\n#   apc &lt;list&gt;\n\n\nThe first argument within the head function is our data frame df and the second argument is the number of rows we want to have returned. Each row within our data frame corresponds to an article."
  },
  {
    "objectID": "OpenAlex.html#data-wrangling-with-the-tidyverse",
    "href": "OpenAlex.html#data-wrangling-with-the-tidyverse",
    "title": "OpenAlex",
    "section": "Data wrangling with the tidyverse",
    "text": "Data wrangling with the tidyverse\nBefore analysing the OpenAlex data, we will have a closer look at the publisher and apc columns and perform some data wrangling tasks.\nTo get an overview of the publishers present in our dataframe and the number of articles per publisher, we will use three tidyverse functions and the pipe operator %&gt;% (magrittr pipe) or |&gt; (base R pipe).\nThe pipe operator allows us to take e.g. a data frame or the result of a function and pass it to another function. If we type the name of our data frame followed by the pipe operator that means we don’t have to specify which data we want a function to be performed on, when we call it after the pipe operator.\nThe group_by function allows us to group data in our data frame df by one or more variables. In this case we will group the data frame by the OpenAlex provided id for the publisher in our host_organization column and the publisher name in our host_organization_name. This allows us to generate aggregate statistics for the publishers in our data frame.\nThe summarise function allows us to calculate summary statistics for each group. In this case we will use the n function to count the number of observations in each group, and the result is stored in a new variable called n.\nThe arrange function is used to sort the data based on the n variable and the desc function lets us determine that the ordering should be in descending order. This means that the groups with the highest number of observations will appear at the top of the output.\n\ndf %&gt;%\n  group_by(host_organization, host_organization_name) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 443 × 3\n# Groups:   host_organization [443]\n   host_organization                host_organization_name                     n\n   &lt;chr&gt;                            &lt;chr&gt;                                  &lt;int&gt;\n 1 https://openalex.org/P4310320990 Elsevier BV                             2506\n 2 https://openalex.org/P4310320595 Wiley                                   2121\n 3 https://openalex.org/P4310319900 Springer Science+Business Media         1395\n 4 &lt;NA&gt;                             &lt;NA&gt;                                    1127\n 5 https://openalex.org/P4310310987 Multidisciplinary Digital Publishing …  1073\n 6 https://openalex.org/P4310319908 Nature Portfolio                         650\n 7 https://openalex.org/P4310320527 Frontiers Media                          506\n 8 https://openalex.org/P4310311648 Oxford University Press                  481\n 9 https://openalex.org/P4310319965 Springer Nature                          417\n10 https://openalex.org/P4310320006 American Chemical Society                388\n# ℹ 433 more rows\n\n\nThe output shows us some important things about the data:\n\nThere is a significant amount of articles that don’t have any publisher assigned. We can’t cover data cleaning tasks in-depth in this notebook but want to point out that this is something worth investigating further. Questions that could be asked are: Do these articles have a DOI? Were these articles misclassified in any way? Can the publisher information got lost for some reason? Are there any other inconsistencies with these articles? Can I disregard some or all of the articles?\nPublisher names are at least in some cases not standardized or aggregated to a single publishing house. The approach taken to represent the publishing structure, i.e. listing imprints or subsidiaries separately or under the main publisher name, and the point in time of the analysis, have an influence of the results, e.g. because of changes in ownership (see also Scheidt 2025).\n\nAs an example we will look at the publisher names in our data frame that contain Springer or Nature. We will use the filter function from the tidyverse that lets us filter articles that fulfil the condition we specify in combination with the grepl function that allows to search for patterns. In this case we will use a regular expression as the pattern to search for.\n\ndf %&gt;%\n  group_by(host_organization, host_organization_name) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n)) %&gt;%\n  filter(grepl(\"^Springer|Nature\", host_organization_name))\n\n# A tibble: 8 × 3\n# Groups:   host_organization [8]\n  host_organization                host_organization_name                n\n  &lt;chr&gt;                            &lt;chr&gt;                             &lt;int&gt;\n1 https://openalex.org/P4310319900 Springer Science+Business Media    1395\n2 https://openalex.org/P4310319908 Nature Portfolio                    650\n3 https://openalex.org/P4310319965 Springer Nature                     417\n4 https://openalex.org/P4310319986 Springer VS                          28\n5 https://openalex.org/P4310320108 Springer Nature (Netherlands)         9\n6 https://openalex.org/P4310319972 Springer International Publishing     3\n7 https://openalex.org/P4310321666 Springer Vienna                       2\n8 https://openalex.org/P4310320090 Springer Medizin                      1\n\n\nIf we want to replace the Springer name variants with Springer Nature as publisher name, we can use the mutate function that lets us transform a column in our data frame in combination with the str_replace_all function that lets us replace string values that follow a pattern we specify to do so.\n\ndf %&gt;%\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\")) %&gt;%\n  group_by(host_organization_name) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 434 × 2\n   host_organization_name                             n\n   &lt;chr&gt;                                          &lt;int&gt;\n 1 Elsevier BV                                     2506\n 2 Springer Nature                                 2505\n 3 Wiley                                           2121\n 4 &lt;NA&gt;                                            1127\n 5 Multidisciplinary Digital Publishing Institute  1073\n 6 Frontiers Media                                  506\n 7 Oxford University Press                          481\n 8 American Chemical Society                        388\n 9 American Physical Society                        350\n10 Taylor & Francis                                 326\n# ℹ 424 more rows\n\n\nBe aware that this data transformation only applies to the publisher name column and not the OpenAlex provided publisher id column. We would need to perform a separate transformation step to align both. Additionally, we did not permanently rename the publisher name values in our data frame. To do this we can either override our data frame df or create a new data frame by assigning the output with the &lt;- operator.\n\ndf &lt;- df %&gt;%\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\"))\n\ndf2 &lt;- df %&gt;%\n  mutate(host_organization_name = str_replace_all(host_organization_name, \"^Springer.*$|Nature.*$\", \"Springer Nature\"))\n\nTo access the apc values in our data frame we will use the unnest_wider, unnest_longer, and pivot_wider functions from the tidyverse with the apc column.\nThe unnest_wider function allows us to turn each element of a list-column into a column. We will further use the select function to print only the resulting apc columns.\n\ndf %&gt;%\n  unnest_wider(apc, names_sep = \".\") %&gt;%\n  select(starts_with(\"apc\"))\n\n# A tibble: 15,952 × 6\n      apc.type   apc.value apc.currency apc.value_usd apc.provenance apc.1\n   &lt;list&lt;chr&gt;&gt; &lt;list&lt;dbl&gt;&gt;  &lt;list&lt;chr&gt;&gt;   &lt;list&lt;dbl&gt;&gt;    &lt;list&lt;chr&gt;&gt; &lt;lgl&gt;\n 1         [2]         [2]          [2]           [2]            [2] NA   \n 2         [2]         [2]          [2]           [2]            [2] NA   \n 3         [2]         [2]          [2]           [2]            [2] NA   \n 4                                                                   NA   \n 5         [2]         [2]          [2]           [2]            [2] NA   \n 6         [2]         [2]          [2]           [2]            [2] NA   \n 7                                                                   NA   \n 8         [2]         [2]          [2]           [2]            [2] NA   \n 9                                                                   NA   \n10         [2]         [2]          [2]           [2]            [2] NA   \n# ℹ 15,942 more rows\n\n\nThe output shows that the values in the apc columns are lists, this is, because OpenAlex provides information for APC list prices and prices of APCs that were actually paid, when available. To transform the lists into single value cells we will use the unnest_longer function that does precisely that.\n\ndf %&gt;%\n  unnest_wider(apc, names_sep = \".\") %&gt;%\n  unnest_longer(c(apc.type, apc.value, apc.currency, apc.value_usd, apc.provenance)) %&gt;%\n  select(id, starts_with(\"apc\"))\n\n# A tibble: 22,044 × 7\n   id         apc.type apc.value apc.currency apc.value_usd apc.provenance apc.1\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;          &lt;lgl&gt;\n 1 https://o… list         10100 USD                  10100 &lt;NA&gt;           NA   \n 2 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 3 https://o… list          3970 USD                   3970 &lt;NA&gt;           NA   \n 4 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 5 https://o… list          9080 USD                   9080 &lt;NA&gt;           NA   \n 6 https://o… paid            NA &lt;NA&gt;                    NA &lt;NA&gt;           NA   \n 7 https://o… list          3690 EUR                   4790 &lt;NA&gt;           NA   \n 8 https://o… paid          3690 EUR                   4790 &lt;NA&gt;           NA   \n 9 https://o… list          9750 EUR                  11690 &lt;NA&gt;           NA   \n10 https://o… paid          9750 EUR                  11690 &lt;NA&gt;           NA   \n# ℹ 22,034 more rows\n\n\nThe output shows that we now have multiple rows for the same id. To transform the data frame to single rows for each id we will use the pivot_wider function that allows us to increase the number of columns and decrease the number of rows.\n\ndf %&gt;%\n  unnest_wider(apc, names_sep = \".\") %&gt;%\n  unnest_longer(c(apc.type, apc.value, apc.currency, apc.value_usd, apc.provenance)) %&gt;%\n  pivot_wider(id_cols = id, names_from = apc.type, values_from = c(apc.value, apc.currency, apc.value_usd, apc.provenance))\n\n# A tibble: 11,022 × 9\n   id          apc.value_list apc.value_paid apc.currency_list apc.currency_paid\n   &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;            \n 1 https://op…          10100             NA USD               &lt;NA&gt;             \n 2 https://op…           3970             NA USD               &lt;NA&gt;             \n 3 https://op…           9080             NA USD               &lt;NA&gt;             \n 4 https://op…           3690           3690 EUR               EUR              \n 5 https://op…           9750           9750 EUR               EUR              \n 6 https://op…          10100             NA USD               &lt;NA&gt;             \n 7 https://op…          10100             NA USD               &lt;NA&gt;             \n 8 https://op…           1800           1800 USD               USD              \n 9 https://op…           9750           9750 EUR               EUR              \n10 https://op…           3920           3920 GBP               GBP              \n# ℹ 11,012 more rows\n# ℹ 4 more variables: apc.value_usd_list &lt;dbl&gt;, apc.value_usd_paid &lt;dbl&gt;,\n#   apc.provenance_list &lt;chr&gt;, apc.provenance_paid &lt;chr&gt;\n\n\nNow we can access the apc information provided by OpenAlex. In this notebook we won’t analyse APC information any further. If you are interested in APC analysis, we offer a notebook showing how to analyse APC information using the OpenAPC data set at: https://oa-datenpraxis.de/OpenAPC.html"
  },
  {
    "objectID": "OpenAlex.html#analysing-institutional-open-access-performance",
    "href": "OpenAlex.html#analysing-institutional-open-access-performance",
    "title": "OpenAlex",
    "section": "Analysing institutional open access performance",
    "text": "Analysing institutional open access performance\nIn the following sections, we will analyse the data to address our question and generate visualizations. This notebook can’t provide an in-depth analysis, but it will demonstrate how to apply some useful functions from base R and the tidyverse to gain insights from the data and show how to create visualisations using the ggplot2 package (Wickham 2016).\n\nHow many of the institutions publication are open access?\nTo determine total number of open access publications of the research organization, we are using the sum function on the is_oa column. This column contains boolean values (true or false) and the sum function will sum up all rows that contain true values.\n\nsum(df$is_oa, na.rm = T)\n\n[1] 10668\n\n\nWe also provided the na.rm=T argument to the sum function which causes NA values to be removed.\nWhen we check for NA values in the is_oa column using the is.na function, we see that there are 21 articles where the open access status is not determined.\n\nsum(is.na(df$is_oa))\n\n[1] 21\n\n\nTo determine the overall open access share over all publication years in our data frame, we divide the total number of open access publications by the total number of publications. We calculate the latter using the n_distinct function on our id column.\n\nround(sum(df$is_oa, na.rm = T) / n_distinct(df$id) * 100, 2)\n\n[1] 66.88"
  },
  {
    "objectID": "OpenAlex.html#how-are-open-access-publications-distributed-across-journals",
    "href": "OpenAlex.html#how-are-open-access-publications-distributed-across-journals",
    "title": "OpenAlex",
    "section": "How are open access publications distributed across journals?",
    "text": "How are open access publications distributed across journals?\nTo analyse the distribution of open access articles across journals we will calculate the total number of articles (n_articles), the total number of open access articles (n_oa_articles) and the total number of closed articles (n_closed_articles) per journal. We will again use the group_by, summarise and arrange functions. However, since we noticed that 21 articles have an undetermined open access status, we will first filter out all rows with NA values in the is_oa column. We will also group the data by the source_display_name column to generate aggregate statistics for the journals.\n\ndf %&gt;%\n  filter(!is.na(is_oa)) %&gt;%\n  group_by(source_display_name) %&gt;%\n  summarise(\n    n_articles = n(),\n    n_oa_articles = sum(is_oa),\n    n_closed_articles = n_articles - n_oa_articles\n  ) %&gt;%\n  arrange(desc(n_oa_articles))\n\n# A tibble: 4,156 × 4\n   source_display_name                n_articles n_oa_articles n_closed_articles\n   &lt;chr&gt;                                   &lt;int&gt;         &lt;int&gt;             &lt;int&gt;\n 1 Scientific Reports                        221           221                 0\n 2 Astronomy and Astrophysics                219           215                 4\n 3 Journal of High Energy Physics            173           173                 0\n 4 Nature Communications                     170           170                 0\n 5 PLoS ONE                                  124           123                 1\n 6 The European Physical Journal C            97            97                 0\n 7 Forests                                    95            95                 0\n 8 Angewandte Chemie                         103            92                11\n 9 International Journal of Molecula…         84            84                 0\n10 &lt;NA&gt;                                      414            84               330\n# ℹ 4,146 more rows\n\n\nThe results show that 414 articles have no journal assigned within our data frame. This could indicate that more data cleaning needs to be performed. The results further show that the top three journals in terms of overall publication volume are SSRN Electronic Journal, Scientific Reports, and Astronomy and Astrophysics, while in terms of open access publication volume the top three journals are Scientific Reports, Astronomy and Astrophysics, and Journal of High Energy Physics.\nWe can further explore the open access status distribution for the articles. We will do this on the example of the top three journals in terms of open access publication volume.\n\ndf %&gt;%\n  filter(source_display_name %in% c(\"Scientific Reports\", \"Astronomy and Astrophysics\", \"Journal of High Energy Physics\")) %&gt;%\n  group_by(source_display_name, is_oa, oa_status) %&gt;%\n  summarise(n = n())\n\n# A tibble: 8 × 4\n# Groups:   source_display_name, is_oa [4]\n  source_display_name            is_oa oa_status     n\n  &lt;chr&gt;                          &lt;lgl&gt; &lt;chr&gt;     &lt;int&gt;\n1 Astronomy and Astrophysics     FALSE closed        1\n2 Astronomy and Astrophysics     FALSE green         3\n3 Astronomy and Astrophysics     TRUE  bronze       95\n4 Astronomy and Astrophysics     TRUE  green         1\n5 Astronomy and Astrophysics     TRUE  hybrid      119\n6 Journal of High Energy Physics TRUE  diamond     168\n7 Journal of High Energy Physics TRUE  green         5\n8 Scientific Reports             TRUE  gold        221\n\n\nThe results show that there are some data inconsistencies for the Astronomy and Astrophysics journal regarding the green open access status. Furthermore Scientific Reports appears to be a true gold open access journal.\n\nHow does the number of open access publications evolve over time?\nWe can combine functions from the tidyverse and ggplot2 to visualise the development of open access over time.\nFirst, we group the data by publication year and open access status. We will then compute the number of articles in each group. In the ggplot function, we assign the publication year column to the x axis and the number of articles to the y axis. We choose point (geom_point) and line (geom_line) graph types to mark the distinct values of n and have them connected by lines. Both are provided with a colour aesthetic which is set to our open access status column. This will result in different colours being assigned to the points and lines for the different open access status values. With the theme_minimal option we are applying a minimal theme for the plot appearance.\n\ndf %&gt;%\n  group_by(publication_year, oa_status) %&gt;%\n  summarise(n = n(), .groups = \"keep\") %&gt;%\n  ggplot(aes(x = publication_year, y = n)) +\n  geom_line(aes(colour = oa_status)) +\n  geom_point(aes(colour = oa_status)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can further choose to visualise the open access distribution over time in terms of percentages. For this we first calculate the share of each open access status per publication year and create a new column using the mutate function that stores these values. We pipe the result through to the ggplot function assigning the publication year column to the x axis and the share to the y axis. We assign the oa_status column to the fill argument which will plot a different colour for each open access status. For this plot we choose a bar chart (geom_bar) graph type and again apply the minimal theme.\n\ndf %&gt;%\n  group_by(publication_year, oa_status) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(perc = count / sum(count) * 100) %&gt;%\n  ggplot(aes(x = publication_year, y = perc, fill = oa_status)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal()"
  },
  {
    "objectID": "OpenAlex.html#exercises",
    "href": "OpenAlex.html#exercises",
    "title": "OpenAlex",
    "section": "Exercises",
    "text": "Exercises\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe following exercises focus on open access publications in regard to publishers and journals. The code is presented in interactive code blocks. You can adapt the code and run it by clicking on run code."
  },
  {
    "objectID": "OpenAlex.html#aggregate-statistics-for-publishers",
    "href": "OpenAlex.html#aggregate-statistics-for-publishers",
    "title": "OpenAlex",
    "section": "Aggregate statistics for publishers",
    "text": "Aggregate statistics for publishers\nBefore, we analysed the distribution of open access articles across journals. Below is a copy of the corresponding code. Adapt the code to give you aggregate statistics for publishers instead of journals.\n\n Interactive editor Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhich publishers are among the top three in terms of overall publication volume and in terms of open access publication volume? Do you notice any interesting patterns?"
  },
  {
    "objectID": "OpenAlex.html#visuzlisation-of-open-access-disctribution-by-top-three-publishers",
    "href": "OpenAlex.html#visuzlisation-of-open-access-disctribution-by-top-three-publishers",
    "title": "OpenAlex",
    "section": "Visuzlisation of open access disctribution by top three publishers",
    "text": "Visuzlisation of open access disctribution by top three publishers\nNow, see if you can adapt the code we used to visualise the open access share over time to show you the open access share for the top three publishers in terms of open access publication volume.\n\n Interactive editor Hint Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint: You’ll want to change something in the code so that you filter first based on the publisher names of the top three publishers before you perform the grouping. You can reuse code that was already introduced in the notebook.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "datenschutz.html",
    "href": "datenschutz.html",
    "title": "Datenschutz",
    "section": "",
    "text": "Personenbezogenen Daten werden über die Website weder automatisch noch manuell direkt gesammelt, gespeichert und verarbeitet.\nDiese Website enthält jedoch Links oder Schaltflächen, die zu Diensten Dritter wie Mastodon oder E-Mail führen. Die Nutzung dieser Funktionen kann zu einer Datenerfassung führen. Wenn Sie auf diese Schaltflächen, Tools oder Inhalte zugreifen, werden möglicherweise automatisch bestimmte Browserinformationen an den Dienstanbieter gesendet. Bitte lesen Sie die Datenschutzerklärungen der Dienstanbieter für weitere Informationen.\nDiese Website wird auf GitHub Pages gehostet. GitHub kann bei der Interaktion mit seinen Diensten personenbezogene Daten erfassen. Weitere Informationen finden Sie in der GitHub-Datenschutzerklärung.\nWeitere Informationen finden Sie auch in der Datenschutzerklärung zu den Webseiten der Humboldt-Universität zu Berlin.\n\n\n\n Back to top"
  },
  {
    "objectID": "aps/AP3.html#beschreibung",
    "href": "aps/AP3.html#beschreibung",
    "title": "AP 3 Open Access in institutionellen Rankings",
    "section": "Beschreibung",
    "text": "Beschreibung\nInstitutionelle Rankings genießen eine hohe Aufmerksamkeit bei wissenschaftspolitischen Entscheidungsträgern und in der Öffentlichkeit, weil es ihnen gelingt, wissenschaftliche Einrichtungen allgemeinverständlich und übersichtlich miteinander zu vergleichen. Trotz vielzähliger Kritikpunkte lassen sich daher Rankings als ein Maßstab der Wahrnehmung wissenschaftlicher Einrichtungen nicht ignorieren und spielen eine entsprechende Rolle beim institutionellen Informationsmanagement.\nDas AP 3 berücksichtigt, dass OA verstärkt als Vergleichsdimension in Rankings auftaucht, etwa im Leiden Ranking of the CWTS, dem COKI Open Access Dashboard und dem Scimago Institutions Ranking."
  },
  {
    "objectID": "aps/AP5.html#beschreibung",
    "href": "aps/AP5.html#beschreibung",
    "title": "AP 5 Synopse",
    "section": "Beschreibung",
    "text": "Beschreibung\nVoraussetzung für die Gestaltung der OA-Transformation ist ein gemeinsames Verständnis einer wissenschaftsgeleiteten Datenpraxis. Diese Praxis umfasst den Umgang mit Daten in wissenschaftlichen Einrichtungen im Allgemeinen (AP 1), die Analyse und Bewertung von Daten im Rahmen von Verlagsverträgen (AP 2), den Umgang mit Daten zu OA im institutionellen Rankings (AP 3) sowie die Erhebung von Daten zu OA für das Reporting (AP 4). Entsprechend des Anliegens der Sicherung von Datensouveränität in der Wissenschaft wird auf Basis der Erkenntnisse in den APs 1, 2, 3 und 4 im AP 5 eine Synopse erstellt. Auf Grundlage dieser Synopse (T5.1) werden Empfehlungen formuliert (T5.2). Anliegen ist es, die Erkenntnisse der vorhergehenden APs zusammenzuführen und deren strategische Dimension herauszuarbeiten. Als Ergebnis werden zusammenfassende Empfehlungen veröffentlicht (T5.3), die sich an Entscheider:innen in Universitäten, außeruniversitären Forschungseinrichtungen, Förderorganisationen und der Wissenschaftspolitik wenden. Von besonderer Bedeutung ist hier der integrative Blick, der die Arbeiten im Projekt zusammenfasst und die Interaktionen zwischen den APs herausstellt. Hierbei werden auch aktuelle wissenschaftspolitische Empfehlungen (z. B. von Allianz, EU, UNESCO, WR, Science Europe) in Beziehung zu den Ergebnissen der vorhergehenden APs gesetzt. Somit wirkt dieses AP als Impuls für die zukünftige Gestaltung der OA-Transformation."
  },
  {
    "objectID": "aps/AP8.html#beschreibung",
    "href": "aps/AP8.html#beschreibung",
    "title": "AP 8 Netzwerke",
    "section": "Beschreibung",
    "text": "Beschreibung\nDie Arbeit mit Daten zur OA-Transformation wird häufig von verschiedenen Akteuren in einer wissenschaftlichen Einrichtung umgesetzt. So befassen sich z. B. Professionals wie OA-Beauftrage, Bibliothekar:innen in der Erwerbung und Lizenzierung, Forschungsreferent:innen und Akteur:innen im Bereich der Forschungsförderung mit Aspekten der Datenarbeit rund um OA. Anliegen des APs ist es, den Dialog zu definierten Fragestellungen über Berufsprofile hinaus zu ermöglichen und damit aktiv den inter- und transdisziplinären Diskurs zur Datenarbeit rund um OA zu ermöglichen. Das Projekt initiiert die Netzwerke und organisiert sie mit je drei digitalen Workshops in der Projektlaufzeit. Darüber hinaus wird eine Mailingliste für die Netzwerke organisiert und somit ein Anstoß zur längerfristigen Kooperation gegeben. Zum Projektende wird mit weiteren Stakeholdern, wie z. B. der Konferenz der informations- und bibliothekswissenschaftlichen Ausbildungs- und Studiengänge (KIBA) eruiert, inwiefern die behandelten Themen in weiteren Gremien und Netzwerken fortgeführt werden können."
  },
  {
    "objectID": "aps/AP7.html#beschreibung",
    "href": "aps/AP7.html#beschreibung",
    "title": "AP 7 Werkzeuge",
    "section": "Beschreibung",
    "text": "Beschreibung\nZur Erhebung, Analyse und Visualisierung von Daten rund um die OA-Transformation gibt es mittlerweile ein großes Angebot an Werkzeugen. Neben den bereits etablierten Diensten wie dem Hybrid Open Access Dashboard (HOAD), OpenAPC und Open Access Monitor sind dies z. B.\n\nAPI-Clients für den computergestützten Zugriff auf offene Datenquellen (z. B. Clients von rOpenSci rund um Publikationsanalysen mit R)\nkostenpflichtige Werkzeuge wie z. B. Unsub, ein Tool für Bibliotheken zur Bewertung von Verlagsangeboten anhand lokaler Nutzungsdaten.\nkostenpflichtige Werkzeuge wie ChronosHub, Oable, OAMetrix und OA Switchboard rund um das APC-Management.\nDashboards zur Datenvisualisierung wie das COKI Open Access Dashboard, das Charité Open Access Dashboard oder das Hamburg Open Science Dashboard.\n\nDa es bisher keine Übersicht dieser vielfältigen Werkzeuge gibt und es bisher keine systematischen Aus- und Weiterbildungsverfahren im Bereich Scholarly Communication Analytics gibt, soll in AP 5 eine digitale Toolbox aufgebaut werden. Diese informiert über Werkzeuge der Datenarbeit rund um die OA- Transformation. Ausgehend von einer Recherche werden die Werkzeuge durch ein zu entwickelndes Metadatenschema beschrieben. Dieses Schema soll die Auffindbarkeit und Bewertung der Werkzeuge unterstützen. Die so entstehende Toolbox wird auf der Webseite des Projektes präsentiert. Nach Ende des Vorhabens wird die Kuration durch das Helmholtz Open Science Office fortgeführt. Die Toolbox wird in englischer Sprache betrieben."
  },
  {
    "objectID": "OpenAPC.html",
    "href": "OpenAPC.html",
    "title": "OpenAPC",
    "section": "",
    "text": "Note\n\n\n\nDieses Notebook wird nur auf English angeboten"
  },
  {
    "objectID": "OpenAPC.html#the-github-repository",
    "href": "OpenAPC.html#the-github-repository",
    "title": "OpenAPC",
    "section": "The GitHub repository",
    "text": "The GitHub repository\nThe project is organized in a GitHub repository. You can find and download csv-files with payment information for individual institutions in the folder data."
  },
  {
    "objectID": "OpenAPC.html#the-olap-server",
    "href": "OpenAPC.html#the-olap-server",
    "title": "OpenAPC",
    "section": "The OLAP server",
    "text": "The OLAP server\nThe OLAP server allows programmatic access to and retrieval of OpenAPC data."
  },
  {
    "objectID": "OpenAPC.html#the-dashboard",
    "href": "OpenAPC.html#the-dashboard",
    "title": "OpenAPC",
    "section": "The Dashboard",
    "text": "The Dashboard\nOn the dashboard, you are able to filter the dataset, see a treemap visualization and download data."
  },
  {
    "objectID": "OpenAPC.html#loading-packages",
    "href": "OpenAPC.html#loading-packages",
    "title": "OpenAPC",
    "section": "loading packages",
    "text": "loading packages\nWe will load the dplyr package (Wickham et al. 2023) that provides a lot of additional functionality for data wrangling, and ggplot2 (Wickham 2016) for data visualization.\n\n# Installation of packages if not already installed with\n# install.packages(c(\"dplyr\",\"ggplot2\"))\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "OpenAPC.html#loading-data",
    "href": "OpenAPC.html#loading-data",
    "title": "OpenAPC",
    "section": "loading data",
    "text": "loading data\nWe will load the csv file downloaded from the OpenAPC dashboard and store it in the object df.\n\ndf &lt;- read.csv(\"facts.csv\")"
  },
  {
    "objectID": "OpenAPC.html#structure-of-the-dataset",
    "href": "OpenAPC.html#structure-of-the-dataset",
    "title": "OpenAPC",
    "section": "structure of the dataset",
    "text": "structure of the dataset\nTo get an overview of the structure of our data frame, especially the number of rows (observations) and columns (variables), the individual column names and the data types they contain, we will use the glimpse function from the dplyr package.\n\nglimpse(df)\n\nRows: 4,331\nColumns: 10\n$ X__fact_key__      &lt;chr&gt; \"Charité - Universitätsmedizin Berlin\", \"Charité - …\n$ institution        &lt;chr&gt; \"Charité - Universitätsmedizin Berlin\", \"Charité - …\n$ period             &lt;int&gt; 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 201…\n$ publisher          &lt;chr&gt; \"Wiley-Blackwell\", \"Wiley-Blackwell\", \"Wiley-Blackw…\n$ journal_full_title &lt;chr&gt; \"International Journal of Gynecology & Obstetrics\",…\n$ issn               &lt;chr&gt; \"0020-7292\", \"0909-752X\", \"1552-4825\", \"0906-6705\",…\n$ doi                &lt;chr&gt; \"10.1002/ijgo.13099\", \"10.1111/srt.12800\", \"10.1002…\n$ is_hybrid          &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ country            &lt;chr&gt; \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"DEU\", \"D…\n$ euro               &lt;dbl&gt; 4331.07, 4331.07, 4331.07, 4331.07, 4331.07, 4331.0…\n\n\nThe output shows that our data frame contains a total of 4,331 rows (observations) and 10 columns. Each row in the data frame corresponds to one APC payment. The output also shows that most of the column values are of data type character (chr), the period column values are of type integer (int), the is_hybrid column values are of type logical (lgl) and the euro column values are of type double-precision floating-point (dbl) - a format for decimal numbers. The output also indicates the first values of every column on the right hand side.\nTo look at the first 10 rows of our data frame we are using the head function.\n\nhead(df, 10)\n\n                          X__fact_key__                          institution\n1  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n2  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n3  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n4  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n5  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n6  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n7  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n8  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n9  Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n10 Charité - Universitätsmedizin Berlin Charité - Universitätsmedizin Berlin\n   period       publisher\n1    2019 Wiley-Blackwell\n2    2019 Wiley-Blackwell\n3    2019 Wiley-Blackwell\n4    2019 Wiley-Blackwell\n5    2019 Wiley-Blackwell\n6    2019 Wiley-Blackwell\n7    2019 Wiley-Blackwell\n8    2019 Wiley-Blackwell\n9    2019 Wiley-Blackwell\n10   2019 Wiley-Blackwell\n                                         journal_full_title      issn\n1          International Journal of Gynecology & Obstetrics 0020-7292\n2                              Skin Research and Technology 0909-752X\n3               American Journal of Medical Genetics Part A 1552-4825\n4                                  Experimental Dermatology 0906-6705\n5                              Journal of Internal Medicine 0954-6820\n6                                                Immunology 0019-2805\n7  JDDG Journal der Deutschen Dermatologischen Gesellschaft 1610-0379\n8                                                   Allergy 0105-4538\n9   Journal of Tissue Engineering and Regenerative Medicine 1932-6254\n10            Alcoholism Clinical and Experimental Research 0145-6008\n                    doi is_hybrid country    euro\n1    10.1002/ijgo.13099      TRUE     DEU 4331.07\n2     10.1111/srt.12800      TRUE     DEU 4331.07\n3  10.1002/ajmg.a.61419      TRUE     DEU 4331.07\n4     10.1111/exd.14007      TRUE     DEU 4331.07\n5    10.1111/joim.12985      TRUE     DEU 4331.07\n6     10.1111/imm.13138      TRUE     DEU 4331.07\n7     10.1111/ddg.14013      TRUE     DEU 4331.07\n8     10.1111/all.14015      TRUE     DEU 4331.07\n9     10.1002/term.2948      TRUE     DEU 4331.07\n10   10.1111/acer.14211      TRUE     DEU 4331.07\n\n\nThe first argument within the head function is our data frame df and the second argument is the number of rows we want to have returned. Each row within our data frame corresponds to an article."
  },
  {
    "objectID": "OpenAPC.html#analyzing-and-visualizing-open-access-payments",
    "href": "OpenAPC.html#analyzing-and-visualizing-open-access-payments",
    "title": "OpenAPC",
    "section": "Analyzing and visualizing open access payments",
    "text": "Analyzing and visualizing open access payments\nIn the following sections, we will analyze the data to address our questions and generate visualizations.\n\nHow much did the institution spend on open access publications in total?\nTo determine total open access spending of the research organization, we are using the sum function and apply it to the colum euro. The OpenAPC schema states that this column contains “[t]he APC amount that was paid in EURO. Includes VAT and any discounts”.\n\nsum(df$euro)\n\n[1] 8669107\n\n\nWithout context, this number does not say much. Applying the min and max functions to the column period (“Year of APC payment (YYYY)”), we can see that this sum was accrued over a period of 6 years, from 2018 to 2023.\n\nmin(df$period)\n\n[1] 2018\n\nmax(df$period)\n\n[1] 2023\n\n\nBecause it takes research organizations time to collect and process data on APC payments and submit it to OpenAPC, there is usually a delay in reporting. In this example, data for 2024 is not yet available.\n\n\nHow are payments distributed across journals?\nThe R package dplyr provides a lot of functionality for data wrangling. We can’t go into much detail here, but we will demonstrate how to use some of the most useful functions.\nOne of them is the group_by function. Here, we use it to group the dataset by the column journal_full_title. This will allow us to generate aggregate statistics for articles published within a journal. We then use the pipe operator %&gt;%, which takes output from one function as input for the next function. The input is passed to the summarise function, where we calculate aggregate statistics. For each journal in the dataset, we calculate the total number of articles published (n_articles), the total of APCs paid (sum_apc), the average APC paid per article (avg_apc), and the standard deviation (sd_apc). The last two statistics are rounded to two decimal places. To get a better overview of the data, we then use arrange to sort the result by the total number of articles.\n\ndf %&gt;%\n  group_by(journal_full_title) %&gt;%\n  summarise(\n    n_articles = n(),\n    sum_apc = sum(euro),\n    avg_apc = round(sum_apc / n_articles, 2),\n    sd_apc = round(sd(euro), 2)\n  ) %&gt;%\n  arrange(desc(n_articles))\n\n# A tibble: 923 × 5\n   journal_full_title                          n_articles sum_apc avg_apc sd_apc\n   &lt;chr&gt;                                            &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Scientific Reports                                 232 433492.   1868.   141.\n 2 PLOS ONE                                           134 223456.   1668.   210.\n 3 Frontiers in Immunology                            130 276129.   2124.   516.\n 4 International Journal of Molecular Sciences        124 222282.   1793.   331.\n 5 Journal of Clinical Medicine                       120 212463.   1771.   502.\n 6 Frontiers in Neurology                              70 144595.   2066.   558.\n 7 Cancers                                             66 118423.   1794.   557.\n 8 Allergy                                             61 168277.   2759.   623.\n 9 Frontiers in Psychiatry                             60 128626.   2144.   638.\n10 Frontiers in Physiology                             43  91332    2124    474.\n# ℹ 913 more rows\n\n\nThe results show that Charité paid APCs for 923 journals, as indicated by the number of rows. Most APC payments were made to the journals Scientific Reports, PLOS ONE, and Frontiers in Immunology. The column sd_apc tells us that for some journals, there is a considerable variance in APC payments.\nWe can explore this variance further by visualizing the distribution of APC payments. For this, we will use the packages dplyr and ggplot2. First, we filter the data to focus on the three journals with the most APC payments. We then pass this output to the ggplot function. We assign the column euro to the x axis and the column journal_full_title to the y axis. Next, we define the type of plot we want - here, we choose a box plot to visualize a distribution. Finally, we choose the theme theme_minimal for a simple layout.\n\ndf %&gt;%\n  filter(journal_full_title %in% c(\"Scientific Reports\", \"PLOS ONE\", \"Frontiers in Immunology\")) %&gt;%\n  ggplot(aes(x = euro, y = journal_full_title)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThese box plots show clear differences in the distribution of APC payments. The three journals differ in the median amount of APCs paid - the median is the middle point in a distribution and is visualized by the vertical line in the box plot. We also see that the range of APC payments is highest for Frontiers in Immunology: there are outliers at the bottom and top end of the distribution, as indicated by the dots.\n\n\nHow do payments evolve over the years?\nWe can combine dplyr and ggplot2 to visualize the development of APC payments over time. We will also consider open access types (gold / hybrid).\nFirst, we group the data by period (“Year of APC payment (YYYY)”) and is_hybrid (“Determines if the article has been published in a hybrid journal (TRUE) or in fully/Gold OA journal (FALSE)”). Just like above, we will generate the aggregate statistic n_articles. In the ggplot function, we assign the column period to the x axis, n_articles to the y axis, and is_hybrid to fill - this means that different colours will be assigned to the open access types. We choose the graph type geom_col, a simple bar chart.\n\ndf %&gt;%\n  group_by(period, is_hybrid) %&gt;%\n  summarise(n_articles = n()) %&gt;%\n  ggplot(aes(x = period, y = n_articles, fill = is_hybrid)) +\n  geom_col() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe plot tells us that the number of APC payments has increased between 2018 and 2021 and has dropped off since. We can also see that APC payments for publications in hybrid open access journals have increased considerably between 2019 and 2020. This is likely the result of transformative agreements between German research organizations and publishers."
  },
  {
    "objectID": "OpenAPC.html#aggregate-statistics-for-publishers",
    "href": "OpenAPC.html#aggregate-statistics-for-publishers",
    "title": "OpenAPC",
    "section": "1. Aggregate statistics for publishers",
    "text": "1. Aggregate statistics for publishers\nAbove, we analyzed APC payments by journal. Here is a copy of that code block. See if you can adapt it to give you aggregate statistics for publishers instead.\n\n Interactive editor Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhich publishers received the highest amount of APC payments from Charité? Do you notice any interesting patterns?"
  },
  {
    "objectID": "OpenAPC.html#visuzlization-of-apc-distribution-by-publisher",
    "href": "OpenAPC.html#visuzlization-of-apc-distribution-by-publisher",
    "title": "OpenAPC",
    "section": "2. Visuzlization of APC distribution by publisher",
    "text": "2. Visuzlization of APC distribution by publisher\nNow, see if you can adapt the code above to show you the distribution of APC payments by publisher.\n\n Interactive editor Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "dashboards.html",
    "href": "dashboards.html",
    "title": "Open-Access-Dashboard Collection",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "The content of the OA Datenpraxis website is made available under the Creative Commons Attribution license. The following is a human-readable summary of (and not a substitute for) the full legal text of the CC BY 4.0 license.\nYou are free:\n\nto Share—copy and redistribute the material in any medium or format\nto Adapt—remix, transform, and build upon the material\n\nfor any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\n\nAttribution—You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions—You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. With the understanding that:\n\nNotices:\n\nYou do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\nNo warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "events/dini24_20240919.html",
    "href": "events/dini24_20240919.html",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "",
    "text": "Datum: 19.09.2024\nUhrzeit: 11:15–12:15 Uhr\nProgramm auf der Seite des Veranstalters\nWorkshop Report"
  },
  {
    "objectID": "events/dini24_20240919.html#daten",
    "href": "events/dini24_20240919.html#daten",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "",
    "text": "Datum: 19.09.2024\nUhrzeit: 11:15–12:15 Uhr\nProgramm auf der Seite des Veranstalters\nWorkshop Report"
  },
  {
    "objectID": "events/dini24_20240919.html#beschreibung",
    "href": "events/dini24_20240919.html#beschreibung",
    "title": "Workshop  Transparenz in der Wissenschaft – Strategien für offene Informationsversorgung",
    "section": "Beschreibung",
    "text": "Beschreibung\nSowohl die Open-Access-Strategie des Bundesministeriums für Bildung und Forschung (BMBF), als auch die Empfehlungen der Europäischen Kommission zu OA an die EU-Mitgliedsstaaten fordern wissenschaftliche Einrichtungen auf, die Transparenz rund um vertragliche Vereinbarungen mit Verlagen zu stärken. Auch die Allianz der deutschen Wissenschaftsorganisationen adressiert dieses Thema. In der Praxis wird diese Forderung jedoch bis auf wenige Ausnahmen (z. B. die Offenlegung der DEAL-Verträge) nicht umgesetzt. Während im Bereich der Publikationsgebühren mit der Initiative OpenAPC ein international beachteter Ansatz zur Offenlegung der Mittel geschaffen wurde, steht eine solche Initiative z. B. für Subskriptionskosten noch aus. Vor diesem Hintergrund strebt das DFG-Projekt Transform2Open eine nationale Transparenzinitiative an, die sowohl Subskriptions- als auch Transformations- und OA-Verträge adressiert. Von besonderem Interesse sind der Umgang mit Non-Disclosure-Agreements und aktuelle Hindernisse für Transparenzbestrebungen. Auch praktische Verfahren zur Offenlegung von Kosten sind ein wichtiges Thema. Mit den Bestrebungen zur Öffnung von Forschungsinformationen, z. B. im Rahmen der Initiative „Barcelona Declaration on Open Research Information“, ergeben sich darüber hinaus neue Möglichkeiten der Zusammenführung von Daten über Publikationen und ihre Kosten. Unter dem Tagungsmotto „Gemeinsame Infrastrukturen für eine offene Wissenschaft“ der 25. Jahrestagung der Deutschen Initiative für Netzwerkinformation (DINI) am 19. September 2024 in Potsdam wurden im Rahmen eines World-Café-Workshops thematisiert, welche Aspekte und Einrichtungen für eine prototypische Implementierung einer Transparenzinitiative zunächst fokussiert werden sollten. Gemeinsam wurden Herausforderungen bei der Umsetzung identifiziert, um die Umsetzung in die Praxis vorzubereiten. Der Workshop wurde gemeinsam von den DFG-Projekten Transform2Open und OA Datenpraxis angeboten. OA Datenpraxis unterstützt die Strukturbildung für die Open-Access-Transformation auf nationaler Ebene. Eine enge Zusammenarbeit mit Akteur:innen aus dem Projekt DEAL, OpenAPC, openCost und dem OA-Monitor besteht bzw. wird weiter ausgebaut."
  },
  {
    "objectID": "events/oat24_20240910.html",
    "href": "events/oat24_20240910.html",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "",
    "text": "Datum: 10.09.2024\nUhrzeit: 13:30–15:00 Uhr\nRaum: Raum 149\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/oat24_20240910.html#daten",
    "href": "events/oat24_20240910.html#daten",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "",
    "text": "Datum: 10.09.2024\nUhrzeit: 13:30–15:00 Uhr\nRaum: Raum 149\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/oat24_20240910.html#beschreibung",
    "href": "events/oat24_20240910.html#beschreibung",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "Beschreibung",
    "text": "Beschreibung\nVor dem Hintergrund der Definition expliziter Zielmarken für das Open-Access-Publikationsaufkommen durch das Bundesministerium für Bildung und Forschung, einiger Bundesländer und verschiedener weiterer Stakeholder gewinnt Open-Access-Reporting weiter an Bedeutung. Gleichzeitig erschweren Umstände wie die komplexe Datenlage eine flächendeckende Implementierung von Verfahren, und es wird deutlich, dass das Erfassen des Publikationsaufkommens durch die Betrachtung weiterer Indikatoren ergänzt werden sollte, um den unterschiedlichen Typen von Hochschulen und deren fachlicher Ausrichtung besser gerecht zu werden.\nDieser interaktive Workshop richtet sich daher an Mitarbeitende an wissenschaftlichen Einrichtungen, die an der Durchführung von Open-Access-Reporting interessiert sind.\nIm Workshop werden unterschiedliche Ansätze des Open-Access-Reportings beleuchtet und diskutiert sowie anhand praxisnaher Beispiele das konkrete Vorgehen bei der Berichterstattung vermittelt.\nDer Workshop wird mit kurzen Praxisberichten zu Open-Access-Reporting auf Länderebene basierend auf qualitativen und quantitativen Ansätzen durch das Open-Access-Büro Berlin und die Vernetzungs- und Kompetenzstelle Brandenburg eröffnet.\nAnschließend erhalten Teilnehmende anhand eigener Fragestellungen und Analyseszenarien einen Einblick in die Nutzung des Open Access Monitors 1 für das Reporting des Publikationsaufkommens ihrer Einrichtung sowie ergänzender Informationen zu Strategien und Services von wissenschaftlichen Einrichtungen auf Basis des oa.atlas 2.\nAnhand vorbereiteter Impulse diskutieren Teilnehmende in Kleingruppen Chancen und Herausforderungen der vorgestellten Reporting-Ansätze, bevor die Ergebnisse kurz im Plenum vorgestellt werden.\nNach Abschluss des Workshops sind die Teilnehmenden mit verschiedenen Ansätzen des Open-Access-Reportings vertraut und in der Lage, den Open Access Monitor und den oa.atlas für die Erstellung eines Berichts über ihre Open-Access-Aktivitäten sowie das Publikationsaufkommen ihrer Einrichtung zu nutzen.\nAn dem Workshop können maximal 20 Personen (exklusive der Organisator:innen) teilnehmen. Teilnehmende müssen einen eigenen Laptop mitbringen."
  },
  {
    "objectID": "events/oat24_20240910.html#footnotes",
    "href": "events/oat24_20240910.html#footnotes",
    "title": "Workshop  Stand und Perspektive des Open-Access-Reportings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nopen-access-monitor.de↩︎\nopen-access.network/services/oaatlas↩︎"
  },
  {
    "objectID": "events/bid25_20250627.html",
    "href": "events/bid25_20250627.html",
    "title": "Vortrag  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Datum: 27.06.2025\nUhrzeit: 11:00–11:30 Uhr\nSaal: Focke-Wulf Saal\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250627.html#daten",
    "href": "events/bid25_20250627.html#daten",
    "title": "Vortrag  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Datum: 27.06.2025\nUhrzeit: 11:00–11:30 Uhr\nSaal: Focke-Wulf Saal\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250627.html#beschreibung",
    "href": "events/bid25_20250627.html#beschreibung",
    "title": "Vortrag  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "Beschreibung",
    "text": "Beschreibung\nZur strategischen und operativen Gestaltung der Open-Access-Transformation werden Daten zu Publikationen und Kosten benötigt. Der Vortrag stellt Ergebnisse einer Umfrage vor, die im Rahmen des von der Deutschen Forschungsgemeinschaft (DFG) geförderten Projekts OA Datenpraxis im Jahr 2024 durchgeführt wurde. Die Umfrage erhob, wie Daten zu Publikationskosten aktuell an wissenschaftlichen Einrichtungen in Deutschland erfasst werden. Adressiert wurden Vertreter*innen von Universitäten, Fachhochschulen, Instituten außeruniversitärer Forschungseinrichtungen (Fraunhofer-Gesellschaft, Helmholtz-Gemeinschaft, Leibniz-Gesellschaft und Max-Planck-Gesellschaft) sowie Ressortforschungseinrichtungen des Bundes. Von den 583 eingeladenen Personen füllten 258 (44,3 %) den Fragebogen aus. Die Umfrage ist die erste umfassende Erhebung zur Erfassung von Publikationskosten in Deutschland.\nDie Ergebnisse zeigen, dass die Mehrzahl der Befragten Publikationskosten zumindest teilweise erfassen. Die Abläufe sind jedoch nicht überall verbindlich geregelt. 33,1 % der Befragten gaben an, dass Publikationskosten an ihrer Einrichtung dezentral an mehreren Abteilungen in mehreren Systemen erfasst werden. Durchschnittlich sind 2,4 Bereiche einer Einrichtung in die Prozesse involviert. 66,3 % der Befragten bewerteten die Zusammenarbeit der beteiligten Einrichtungen als “sehr gut” oder “eher gut”. schätzen die Erfassung je nach Mittelherkunft unterschiedlich zuverlässig ein, am zuverlässigsten wird der Einsatz von Mitteln bewertet, die von einer zentralen Serviceeinrichtung verwaltet werden. 80,2 % bewerteten den Beitrag der Erfassung von Publikationskosten für die Gestaltung der Open-Access-Transformation als “sehr wichtig” oder “eher wichtig”. Die erfassten Daten sind jedoch nicht an allen Einrichtungen Grundlage strategischer Entscheidungen. Die Umsetzung eines Informationsbudgets bis 2025 wird an den meisten Einrichtungen als unwahrscheinlich angesehen."
  },
  {
    "objectID": "events/bid25_20250626.html",
    "href": "events/bid25_20250626.html",
    "title": "Vortrag  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "",
    "text": "Datum: 26.06.2025\nUhrzeit: 11:00–12:30 Uhr\nSaal: Kaisen Saal (mit Streaming)\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250626.html#daten",
    "href": "events/bid25_20250626.html#daten",
    "title": "Vortrag  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "",
    "text": "Datum: 26.06.2025\nUhrzeit: 11:00–12:30 Uhr\nSaal: Kaisen Saal (mit Streaming)\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250626.html#beschreibung",
    "href": "events/bid25_20250626.html#beschreibung",
    "title": "Vortrag  Offene Metadaten als Bezugspunkt für die Verhandlung und Evaluierung von Open-Access-Transformationsverträgen",
    "section": "Beschreibung",
    "text": "Beschreibung\nDie Georg-August-Universität Göttingen hat am 28. August 2024 die „Barcelona Declaration on Open Research Information“ unterzeichnet. Damit schließt sich die Universität Göttingen namhaften internationalen Wissenschaftsakteuren an, die sich für die Öffnung von Forschungsinformationen einsetzen.\nDer Vortrag stellt zunächst die diesbezüglichen Handlungsfelder der Niedersächsischen Staats- und Universitätsbibliothek Göttingen im Sinne der Prinzipien der Barcelona Declaration kurz vor. Der Schwerpunkt des Vortrags liegt dann auf der Bewertung der Anwendbarkeit offener Metadaten wissenschaftlicher Publikationen für das Monitoring internationaler Open-Access-Transformationsverträge im Vergleich zu proprietären Bibliometriedatenbanken. Die Datenanalyse von mehr als 13.000 hybriden wissenschaftlichen Zeitschriften, die Teil eines Transformationsvertrages sind, aus den offenen Quellen Crossref und OpenAlex sowie den geschlossenen Datenbanken Web of Science und Scopus zeigt Potenziale und Lücken auf. Darauf aufbauend werden Handlungsfelder für den Ausbau offener Metadaten benannt, die Bibliotheken und Verlage im Rahmen von Verhandlungen über Open-Access-Transformationsverträge adressieren können. Insgesamt kommt Open-Access-Transformationsverträgen eine Schlüsselrolle zu, um durch die Bereitstellung offener Metadaten seitens der Verlage das Open-Access-Monitoring zu verbessern und damit den Wandel hin zu offenen Forschungsinformationen im Sinne der Barcelona Declaration zu fördern."
  },
  {
    "objectID": "events.html#konferenzen-tagungen",
    "href": "events.html#konferenzen-tagungen",
    "title": "Veranstaltungen",
    "section": "Konferenzen & Tagungen",
    "text": "Konferenzen & Tagungen\n\nOpen-Access-Tage 2025, 17. – 19. September 2025, Konstanz\n19.09.2025: Workshop – Praktiken und Infrastrukturen des Open-Access-Monitorings"
  },
  {
    "objectID": "events/oat25_20250919.html",
    "href": "events/oat25_20250919.html",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "",
    "text": "Datum: 19.09.2025\nUhrzeit: 09:00–10:30 Uhr\nRaum: Raum C425\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/oat25_20250919.html#daten",
    "href": "events/oat25_20250919.html#daten",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "",
    "text": "Datum: 19.09.2025\nUhrzeit: 09:00–10:30 Uhr\nRaum: Raum C425\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/oat25_20250919.html#beschreibung",
    "href": "events/oat25_20250919.html#beschreibung",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "Beschreibung",
    "text": "Beschreibung\nUnter dem Begriff Open-Access-Monitoring wird die Erfassung und Analyse von Informationen, Publikationen, Kosten und weiteren Parametern des Open-Access-Publizierens verstanden. Mit Blick auf Zielmarken sowie auf die ökonomische Dimension der Open-Access-Transformation gewinnt der Umgang mit diesen Informationen weiter an Relevanz.\nDieser Workshop wird gemeinsam von den DFG-geförderten Projekten OA Datenpraxis 1, openCost 2 und Transform2Open 3 veranstaltet und richtet sich an Professionals, die sich mit Monitoring beschäftigen.\nZiel des Workshops ist es, gemeinsam mit den Teilnehmenden aktuelle Fragestellungen des Open-Access-Monitorings zu diskutieren. Dabei widmet sich der Workshop den folgenden Handlungsfeldern: (1) die Stärkung der Standardisierung im Bereich des Monitorings, (2) die Förderung von Transparenzinitiativen in diesem Bereich, (3) die Weiterentwicklung der Nachnutzungsmöglichkeiten offener Daten – auch im Kontext der Barcelona Declaration.\nDer Workshop beginnt mit einer kurzen Vorstellung der beteiligten Projekte. Anschließend bearbeiten Teilnehmende vorbereitete Impulse im Format World Café. Hierbei diskutieren die Teilnehmenden in Gruppen Fragestellungen zu den oben genannten Aspekten an verschiedenen Stationen im Raum. Anschließend werden die Ergebnisse im Plenum zusammengetragen. Als kollaboratives Tool für die Diskussion und Ergebnissicherung wird ein Etherpad verwendet. Die Ergebnisse werden im Anschluss an die Veranstaltung durch die Organisator:innen in einem Blogpost aufbereitet und kommuniziert.\nAn dem Workshop können maximal 30 Personen teilnehmen. Teilnehmenden wird empfohlen, einen eigenen Laptop mitzubringen."
  },
  {
    "objectID": "events/oat25_20250919.html#footnotes",
    "href": "events/oat25_20250919.html#footnotes",
    "title": "Workshop  Praktiken und Infrastrukturen des Open-Access-Monitorings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://oa-datenpraxis.de↩︎\nhttps://www.opencost.de↩︎\nhttps://www.transform2open.de↩︎"
  },
  {
    "objectID": "events/webinar_20250404.html",
    "href": "events/webinar_20250404.html",
    "title": "OA Datenpraxis Webinar  Offene Metadaten für Hochschulrankings am Beispiel des Leiden Ranking",
    "section": "",
    "text": "Datum: 04.04.2025\nUhrzeit: 10:00–11:00 Uhr\nOrt: Online über Zoom\nRegistrierung unter: https://hu-berlin.zoom-x.de/webinar/register/WN_4_U1o0yDSbOufyh7y_aloQ"
  },
  {
    "objectID": "events/webinar_20250404.html#daten",
    "href": "events/webinar_20250404.html#daten",
    "title": "OA Datenpraxis Webinar  Offene Metadaten für Hochschulrankings am Beispiel des Leiden Ranking",
    "section": "",
    "text": "Datum: 04.04.2025\nUhrzeit: 10:00–11:00 Uhr\nOrt: Online über Zoom\nRegistrierung unter: https://hu-berlin.zoom-x.de/webinar/register/WN_4_U1o0yDSbOufyh7y_aloQ"
  },
  {
    "objectID": "events/webinar_20250404.html#beschreibung",
    "href": "events/webinar_20250404.html#beschreibung",
    "title": "OA Datenpraxis Webinar  Offene Metadaten für Hochschulrankings am Beispiel des Leiden Ranking",
    "section": "Beschreibung",
    "text": "Beschreibung\nOffene Metadaten zu wissenschaftlichen Publikationen spielen auch in Hochschulrankings eine zunehmend wichtige Rolle. Sie ermöglichen nicht nur eine umfassende und transparente Berichterstattung über die Forschungsleistungen von Universitäten, sondern bieten auch vielfältige Nachnutzungsmöglichkeiten.\nIm Webinar wird das einschlägige Leiden Ranking des CWTS vorgestellt, das nun auch offene Metadaten nutzt. Am Beispiel der Universität Konstanz wird anschließend illustriert, wie Universitäten das Ranking nutzen können, um datengestützt über die Forschungs- und Open-Access-Erfolge ihrer Institution nach innen und außen zu informieren.\nWir freuen uns, dass Dr. Nees Jan van Eck (CWTS Leiden) und Dr. Anja Oberländer (Universität Konstanz) ihre Einblicke sowohl aus der Perspektive der Erstellung eines Rankings als auch aus der Anwendungsperspektive mit uns teilen.\nDas Webinar richtet sich an alle Mitarbeiter im Bereich Open Access/Open Science und Leiter von wissenschaftlichen Einrichtungen sowie an Personen, die sich für Wissenschaftsbewertung und Open Access/Open Science interessieren.\n\nProgramm\n\nBegrüßung durch Sophia Dörner (5 Minuten)\nVortrag 1: Nees Jan van Eck (CWTS Leiden) stellt das Leiden Ranking Open Edition mit Fokus auf offene Daten und Open Access als Rankingdimension vor (20 Minuten)\nVortrag 2: Anja Oberländer (Universität Konstanz) stellt die Anwenderperspektive des Leiden Rankings vor und erläutert strategische Ansätze zu Open Access/Open Science (20 Minuten)\nFragen & Diskussion (15 Minuten)"
  },
  {
    "objectID": "events/bid25_20250624.html",
    "href": "events/bid25_20250624.html",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "",
    "text": "Datum: 24.06.2025\nUhrzeit: 16:00–18:00 Uhr\nSaal: Salon London\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250624.html#daten",
    "href": "events/bid25_20250624.html#daten",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "",
    "text": "Datum: 24.06.2025\nUhrzeit: 16:00–18:00 Uhr\nSaal: Salon London\nProgramm auf der Seite des Veranstalters"
  },
  {
    "objectID": "events/bid25_20250624.html#beschreibung",
    "href": "events/bid25_20250624.html#beschreibung",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "Beschreibung",
    "text": "Beschreibung\nDas Ziel des Hands-on Labs ist, eine niedrigschwellige praktische Einführung in die Erstellung eines einfachen Dashboards zur Darstellung des (Open-Access-)Publikationsoutputs wissenschaftlicher Einrichtungen zu geben. Zu diesem Zweck wird Quarto genutzt, ein wissenschaftliches und technisches Open-Source-Publikationssystem, das es ermöglicht, reproduzierbare Artikel, Präsentationen, Dashboards, Websites, Blogs oder Bücher in verschiedenen (Export-)Formaten zu erstellen. Ziel ist die übersichtliche und leicht abrufbare Darstellung von unterschiedlichen OA-bezogenen Daten und ein Beitrag zu einer reproduzierbaren OA Datenpraxis, welche auch im Rahmen des Projekts OA Datenpraxis1 angestrebt und ausgebaut werden. Es wird zu Beginn ein Datensatz für die eigene Institution von OpenAlex2 abgefragt. Anschließend werden gemeinsam die Grundlagen der Verwendung von Quarto zum Laden und Bearbeiten von Daten, zur Erstellung von Visualisierungen und zur Präsentation der Ergebnisse in einem benutzerfreundlichen Dashboard mit R erarbeitet. Vorkenntnisse in der Programmiersprache R oder im Umgang mit Quarto werden nicht vorausgesetzt, sind jedoch hilfreich. Der im Rahmen des Labs verwendete Code wird so erarbeitet, dass er auch ohne Vorkenntnisse genutzt und nachvollzogen werden kann. Bitte bringen Sie einen Laptop mit und erstellen vorab einen Posit Cloud Account3."
  },
  {
    "objectID": "events/bid25_20250624.html#footnotes",
    "href": "events/bid25_20250624.html#footnotes",
    "title": "Hands-on Lab  Open-Access-Monitoring Dashboards mit Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://oa-datenpraxis.de/↩︎\nhttps://openalex.org/↩︎\nhttps://posit.cloud/plans/free↩︎"
  },
  {
    "objectID": "events/webinar_20250328.html",
    "href": "events/webinar_20250328.html",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Datum: 28.03.2025\nUhrzeit: 10:00–11:00 Uhr\nOrt: Online über Zoom\nRegistrierung unter: https://hu-berlin.zoom-x.de/webinar/register/WN_pKTlDzjsQwC7QspLxwMHCg"
  },
  {
    "objectID": "events/webinar_20250328.html#daten",
    "href": "events/webinar_20250328.html#daten",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "",
    "text": "Datum: 28.03.2025\nUhrzeit: 10:00–11:00 Uhr\nOrt: Online über Zoom\nRegistrierung unter: https://hu-berlin.zoom-x.de/webinar/register/WN_pKTlDzjsQwC7QspLxwMHCg"
  },
  {
    "objectID": "events/webinar_20250328.html#beschreibung",
    "href": "events/webinar_20250328.html#beschreibung",
    "title": "OA Datenpraxis Webinar  Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland",
    "section": "Beschreibung",
    "text": "Beschreibung\nIn dem Webinar werden Ergebnisse einer Umfrage vorgestellt, die im Rahmen des von der Deutschen Forschungsgemeinschaft (DFG) geförderten Projekts OA Datenpraxis im Jahr 2024 durchgeführt wurde.\nDie Umfrage, die im Dialog mit Vertreter:innen der DEAL-Untergruppe “Kommunikation” entwickelt wurde, erhob, wie Daten zu Publikationskosten aktuell an wissenschaftlichen Einrichtungen in Deutschland erfasst werden. Adressiert wurden Vertreter:innen von Universitäten, Fachhochschulen, Instituten außeruniversitärer Forschungseinrichtungen sowie Ressortforschungseinrichtungen des Bundes. Von 583 eingeladenen Personen beteiligten sich 258 (44,3 %) an der Umfrage. Die Umfrage ist die erste umfassende Erhebung zur Erfassung von Publikationskosten in Deutschland.\nDieses Webinar richtet sich an Professionals, die sich für Open-Access-Monitoring, insbesondere die Erfassung von Open-Access-Publikationskosten, interessieren.\n\nProgramm\nNach einer Präsentation der Umfrageergebnisse haben Teilnehmende die Möglichkeit, Fragen zur Umfrage zu stellen. Anschließend werden einige zentrale Aspekte der Erfassung von Publikationskosten in einer Paneldiskussion mit Mitgliedern der DEAL-Gruppe erörtert.\n\nBegrüßung durch Heinz Pampel (5 Minuten)\nVorstellung der Umfrageergebnisse durch Dorothea Strecker (30 Minuten)\nQ&A zur Umfrage (10 Minuten)\nPaneldiskussion mit Mitgliedern der DEAL-Gruppe (15 Minuten)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "Das Projekt OA Datenpraxis unterstützt die Strukturbildung für die Open-Access-Transformation an wissenschaftlichen Einrichtungen in Deutschland. Im Fokus stehen die Förderung und Etablierung von Prozessen und Verfahren zur souveränen Datenpraxis bei der Gestaltung der Open-Access-Transformation.\nIm Projekt werden Praktiker:innen in Administration, Bibliothek und anderen Serviceeinrichtungen bei der Professionalisierung ihrer Datenpraxis unterstützt, indem die Organisation, Vernetzung und Standardisierung der jeweiligen Prozesse durch einen koordinierten Ansatz gefördert werden.\n\n\nMit Blick auf die Open-Access-Transformation verfolgt das Projekt die folgenden Ziele:\n\ndie Verbesserung der datenbasierten Steuerung\ndie Stärkung von Kooperationen\ndie Entwicklung von Standards für eine kollaborative Datenpraxis\ndie Minimierung von Abhängigkeiten von kommerziellen Datenquellen\ndie Verbesserung von Informationsangeboten\n\nDurch Erhebungen, Analysen, Validierungen und operative Empfehlungen leisted OA Datenpraxis einen zentralen Beitrag zur Weiterentwicklung der überregionalen Informationsversorgung in Deutschland.\n\n\n\nEine gekürzte Fassung des Projektantrags ist hier veröffentlicht:\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/zenodo.10794298\n\n\n\nDas Projekt OA Datenpraxis ist unter der Projektnummer 528466070 durch die Deutsche Forschungsgemeinschaft gefördert."
  },
  {
    "objectID": "index.html#projektbeschreibung",
    "href": "index.html#projektbeschreibung",
    "title": "OA Datenpraxis",
    "section": "",
    "text": "Das Projekt OA Datenpraxis unterstützt die Strukturbildung für die Open-Access-Transformation an wissenschaftlichen Einrichtungen in Deutschland. Im Fokus stehen die Förderung und Etablierung von Prozessen und Verfahren zur souveränen Datenpraxis bei der Gestaltung der Open-Access-Transformation.\nIm Projekt werden Praktiker:innen in Administration, Bibliothek und anderen Serviceeinrichtungen bei der Professionalisierung ihrer Datenpraxis unterstützt, indem die Organisation, Vernetzung und Standardisierung der jeweiligen Prozesse durch einen koordinierten Ansatz gefördert werden.\n\n\nMit Blick auf die Open-Access-Transformation verfolgt das Projekt die folgenden Ziele:\n\ndie Verbesserung der datenbasierten Steuerung\ndie Stärkung von Kooperationen\ndie Entwicklung von Standards für eine kollaborative Datenpraxis\ndie Minimierung von Abhängigkeiten von kommerziellen Datenquellen\ndie Verbesserung von Informationsangeboten\n\nDurch Erhebungen, Analysen, Validierungen und operative Empfehlungen leisted OA Datenpraxis einen zentralen Beitrag zur Weiterentwicklung der überregionalen Informationsversorgung in Deutschland.\n\n\n\nEine gekürzte Fassung des Projektantrags ist hier veröffentlicht:\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/zenodo.10794298\n\n\n\nDas Projekt OA Datenpraxis ist unter der Projektnummer 528466070 durch die Deutsche Forschungsgemeinschaft gefördert."
  },
  {
    "objectID": "dashboard_uebersicht.html",
    "href": "dashboard_uebersicht.html",
    "title": "OA Dashboards Kontakt",
    "section": "",
    "text": "Mit der wachsenden Bedeutung von Open Access stellt sich die Frage nach dem Anteil am Publikationsaufkommen von Forschungseinrichtungen, Ländern und auch auf globaler Ebene. Im Projekt OA Datenpraxis entwickeln wir eine Übersicht über Dashboards zu Open Access.\nDafür haben wir eine Recherche zu relevanten Dashboards durchgeführt und ein eigenes Metadatenschema zur Indexierung erstellt. Im Mai 2025 haben wir einen Community-Prozess gestartet, um die Sammlung weiterzuentwickeln und auszubauen.\nSie finden die Open-Access-Dashboard-Collection hier und das dazugehörige Metadatenschema hier.\nFalls Sie Änderungsvorschläge haben oder ein Dashboard haben, was hier noch nicht gelistet wird, schreiben Sie uns sehr gerne hier: oa-datenpraxis-dashboards@listserv.dfn.de. Wir freuen uns über jeden Hinweis und tragen neue Dashboards ein.\nFalls Sie selbst tätig werden wollen, finden Sie eine editierbare Version der Dashboard-Collection hier: https://nextcloud.gfz.de/s/QG38J6kEDbJ8DXz Dort können Sie neue Vorschläge selbst eintragen."
  },
  {
    "objectID": "dashboard_uebersicht.html#oa-dashboard-collection",
    "href": "dashboard_uebersicht.html#oa-dashboard-collection",
    "title": "OA Dashboards Kontakt",
    "section": "",
    "text": "Mit der wachsenden Bedeutung von Open Access stellt sich die Frage nach dem Anteil am Publikationsaufkommen von Forschungseinrichtungen, Ländern und auch auf globaler Ebene. Im Projekt OA Datenpraxis entwickeln wir eine Übersicht über Dashboards zu Open Access.\nDafür haben wir eine Recherche zu relevanten Dashboards durchgeführt und ein eigenes Metadatenschema zur Indexierung erstellt. Im Mai 2025 haben wir einen Community-Prozess gestartet, um die Sammlung weiterzuentwickeln und auszubauen.\nSie finden die Open-Access-Dashboard-Collection hier und das dazugehörige Metadatenschema hier.\nFalls Sie Änderungsvorschläge haben oder ein Dashboard haben, was hier noch nicht gelistet wird, schreiben Sie uns sehr gerne hier: oa-datenpraxis-dashboards@listserv.dfn.de. Wir freuen uns über jeden Hinweis und tragen neue Dashboards ein.\nFalls Sie selbst tätig werden wollen, finden Sie eine editierbare Version der Dashboard-Collection hier: https://nextcloud.gfz.de/s/QG38J6kEDbJ8DXz Dort können Sie neue Vorschläge selbst eintragen."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publikationen",
    "section": "",
    "text": "Ferguson, L. M., Pampel, H., Strecker, D., & Meistring, M. (2025). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. Zenodo. https://doi.org/10.5281/zenodo.14505423\n\n\nJahn, N. (2025a). Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata. Scientometrics. https://doi.org/10.1007/s11192-025-05390-3\n\n\nJahn, N. (2025b). How open are hybrid journals included in transformative agreements? Quantitative Science Studies, 6, 242–262. https://doi.org/10.1162/qss_a_00348\n\n\nOberländer, A. (2025). OA Datenpraxis Webinar: Leiden Ranking at the University of Konstanz. https://doi.org/10.5281/zenodo.15593872\n\n\nPampel, H., Stein, L.-M., Mittermaier, B., Strecker, D., Schweighofer, B., & Deinzer, G. (2025). Praktiken und Infrastrukturen des Open-Access-Monitorings. https://doi.org/10.5281/zenodo.17198826\n\n\nSchneider, J., Pampel, H., & Höfting, J. (2025). Data Documentation for: Mapping the Landscape of Open Access Dashboards: A Dataset for Research and Infrastructure Development. Zenodo. https://doi.org/10.5281/zenodo.15593821\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025a). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.17119308\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025b). Wie erfassen wissenschaftliche Einrichtungen Daten zu Publikationskosten? In oa.blog. https://open-access.network/blog/wie-erfassen-wissenschaftliche-einrichtungen-daten-zu-publikationskosten\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025c). Dataset for: Recording of publication costs at research performing institutions in Germany. Zenodo. https://doi.org/10.5281/zenodo.14732554\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025d). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://nbn-resolving.org/urn:nbn:de:0290-opus4-198024\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025e). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. Bibliothek Forschung Und Praxis. https://doi.org/10.1515/bfp-2025-0008\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025f). OA Datenpraxis Webinar: Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.15076512\n\n\nVan Eck, N. J. (2025). OA Datenpraxis Webinar: CWTS Leiden Ranking Open Edition. https://doi.org/10.5281/zenodo.15147838\n\n\nBarbers, I., Kindling, M., Stadler, H., & Strecker, D. (2024). Stand und Perspektive des Open-Access-Reportings. https://doi.org/10.5281/zenodo.13831942\n\n\nFerguson, L. M., Meistring, M., Pampel, H., & Strecker, D. (2024). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. https://doi.org/10.5281/zenodo.13837272\n\n\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/ZENODO.10794298"
  },
  {
    "objectID": "publications.html#publikationen-aus-dem-projekt",
    "href": "publications.html#publikationen-aus-dem-projekt",
    "title": "Publikationen",
    "section": "",
    "text": "Ferguson, L. M., Pampel, H., Strecker, D., & Meistring, M. (2025). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. Zenodo. https://doi.org/10.5281/zenodo.14505423\n\n\nJahn, N. (2025a). Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata. Scientometrics. https://doi.org/10.1007/s11192-025-05390-3\n\n\nJahn, N. (2025b). How open are hybrid journals included in transformative agreements? Quantitative Science Studies, 6, 242–262. https://doi.org/10.1162/qss_a_00348\n\n\nOberländer, A. (2025). OA Datenpraxis Webinar: Leiden Ranking at the University of Konstanz. https://doi.org/10.5281/zenodo.15593872\n\n\nPampel, H., Stein, L.-M., Mittermaier, B., Strecker, D., Schweighofer, B., & Deinzer, G. (2025). Praktiken und Infrastrukturen des Open-Access-Monitorings. https://doi.org/10.5281/zenodo.17198826\n\n\nSchneider, J., Pampel, H., & Höfting, J. (2025). Data Documentation for: Mapping the Landscape of Open Access Dashboards: A Dataset for Research and Infrastructure Development. Zenodo. https://doi.org/10.5281/zenodo.15593821\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025a). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.17119308\n\n\nStrecker, D., Höfting, J., & Pampel, H. (2025b). Wie erfassen wissenschaftliche Einrichtungen Daten zu Publikationskosten? In oa.blog. https://open-access.network/blog/wie-erfassen-wissenschaftliche-einrichtungen-daten-zu-publikationskosten\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025c). Dataset for: Recording of publication costs at research performing institutions in Germany. Zenodo. https://doi.org/10.5281/zenodo.14732554\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025d). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://nbn-resolving.org/urn:nbn:de:0290-opus4-198024\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025e). Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. Bibliothek Forschung Und Praxis. https://doi.org/10.1515/bfp-2025-0008\n\n\nStrecker, D., Pampel, H., & Höfting, J. (2025f). OA Datenpraxis Webinar: Erfassung von Publikationskosten an wissenschaftlichen Einrichtungen in Deutschland. https://doi.org/10.5281/zenodo.15076512\n\n\nVan Eck, N. J. (2025). OA Datenpraxis Webinar: CWTS Leiden Ranking Open Edition. https://doi.org/10.5281/zenodo.15147838\n\n\nBarbers, I., Kindling, M., Stadler, H., & Strecker, D. (2024). Stand und Perspektive des Open-Access-Reportings. https://doi.org/10.5281/zenodo.13831942\n\n\nFerguson, L. M., Meistring, M., Pampel, H., & Strecker, D. (2024). Transparenz in der Wissenschaft: Strategien für offene Informationsversorgung. https://doi.org/10.5281/zenodo.13837272\n\n\nPampel, H., Jahn, N., Bertelmann, R., Horstmann, W., Rothfritz, L., Ferguson, L. M., Schmidt, B., & Stisser, A. (2024). Datenpraxis zur Gestaltung der Open-Access-Transformation - Analyse, Empfehlung, Training & Vernetzung (OA Datenpraxis). https://doi.org/10.5281/ZENODO.10794298"
  },
  {
    "objectID": "publications.html#vorarbeiten-der-projektpartner",
    "href": "publications.html#vorarbeiten-der-projektpartner",
    "title": "Publikationen",
    "section": "Vorarbeiten der Projektpartner",
    "text": "Vorarbeiten der Projektpartner\n\n\nJahn, N. (2024). How open are hybrid journals included in transformative agreements? arXiv. https://doi.org/10.48550/arXiv.2402.18255\n\n\nFraser, N., Hobert, A., Jahn, N., Mayr, P., & Peters, I. (2023). No deal: German researchers’ publishing and citing behaviors after big deal negotiations with elsevier. Quantitative Science Studies, 4(2), 325–352. https://doi.org/10.1162/qss_a_00255\n\n\nTaubert, N., Hobert, A., Jahn, N., Bruns, A., & Iravani, E. (2023). Understanding differences of the OA uptake within the german university landscape (2010–2020): Part 1—journal-based OA. Scientometrics, 128(6), 3601–3625. https://doi.org/10.1007/s11192-023-04716-3\n\n\nJahn, N., Matthias, L., & Laakso, M. (2022). Toward transparency of hybrid open access through publisher-provided metadata: An article-level study of elsevier. Journal of the Association for Information Science and Technology, 73(1), 104–118. https://doi.org/10.1002/asi.24549\n\n\nPampel, H. (2022). From library budget to information budget: Fostering transparency in the transformation towards open access. Insights the UKSG Journal, 35, 8. https://doi.org/10.1629/uksg.576\n\n\nHobert, A., Jahn, N., Mayr, P., Schmidt, B., & Taubert, N. (2021). Open access uptake in germany 2010–2018: Adoption in a diverse research landscape. Scientometrics, 126(12), 9751–9777. https://doi.org/10.1007/s11192-021-04002-0"
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "Impressum",
    "section": "",
    "text": "Institut für Bibliotheks- und Informationswissenschaft, Humboldt-Universität zu Berlin\nDorotheenstr. 26\n10117 Berlin\nKontakt\nProf. Dr. Heinz Pampel\nE-Mail: heinz.pampel@hu-berlin.de\nTelefon: (030) 2093 70977\n\n\n\n Back to top"
  },
  {
    "objectID": "aps/AP6.html#beschreibung",
    "href": "aps/AP6.html#beschreibung",
    "title": "AP 6 Trainings",
    "section": "Beschreibung",
    "text": "Beschreibung\nDie Carpentries (bestehend aus Data, Library und Software Carpentry) sind eine Methode, in grundlegende Datenkompentenzen einzuführen. Hauptaugenmerk liegt dabei auf dem gemeinschaftlichen Erlernen IT-gestützter Verfahren zur Lösung praktischer Probleme. In Deutschland unterstützen sowohl bibliothekarische Fachverbände als auch wissenschaftliche Einrichtungen die Carpentries-Community über eine Mitgliedschaft. So ist die SUB Göttingen seit 2019 Mitglied und bildet am Campus Göttingen jährlich bis zu fünf Instruktoren aus und organisiert regelmäßig Carpentries Workshops, die in erster Linie Nachwuchswissenschaftler:innen und Bibliothekar:innen adressieren. Ziel des AP ist es, Trainings mit spezifischem Fokus auf die Datenpraxis zur Gestaltung der OA- Transformation als Teil von Library Carpentry zu entwerfen, zu testen und iterativ weiterzuentwickeln. Die Zielgruppe umfasst Professionals des Bereichs OA-Transformation und Forschungsadministration. Innerhalb eines Carpentry-Trainings lassen sich nicht sämtliche datenanalytische Aspekte abdecken. Vielmehr geht es darum, offene und wissenschaftsnahe Tools und Vorgehensweisen einzuführen und deren Anwendung zu erproben (Wilson et al., 2017). Die Aufgaben des AP orientieren sich an dem Lebenszyklus der Carpentries Lessons und starten im 2. Projektjahr."
  },
  {
    "objectID": "aps/AP2.html#beschreibung",
    "href": "aps/AP2.html#beschreibung",
    "title": "AP 2 Verlagsverträge",
    "section": "Beschreibung",
    "text": "Beschreibung\nOA-Transformationsverträge sind in Bezug auf offene Metadaten trotz Standardisierungsinitiativen wie ESAC heterogen gestaltet (Borrego et al., 2021; Jahn et al., 2022; Marques et al., 2019). Zugleich bieten Verlage unterschiedlich ausgeprägte Metadaten- und Forschungsservices zusätzlich zur OA-Stellung der Artikel und der zentralen Rechnungslegung an. Ziel des AP ist es, Verlagsverträge bezogen auf offene Metadaten und datenanalytische Forschungsservices zu analysieren und Best Practices zu identifizieren. Dadurch soll der Wettbewerb zwischen den Verlagen befördert werden."
  },
  {
    "objectID": "aps/AP4.html#beschreibung",
    "href": "aps/AP4.html#beschreibung",
    "title": "AP 4 Open-Access-Reporting",
    "section": "Beschreibung",
    "text": "Beschreibung\nIn der Digital-Strategie des Bundesministeriums für Bildung und Forschung (BMBF) heißt es: „Bis zum Jahr 2025 werden 70 Prozent aller neu erscheinenden wissenschaftlichen Publikationen in Deutschland ausschließlich oder zusätzlich im Wege des Open Access veröffentlicht.“ (Bundesministerium für Bildung und Forschung, 2019, S. 37). Über diese nationale OA-Zielmarke hinaus haben einzelne Bundesländer spezifische OA-Zielmarken definiert. Im „Monitoring-Bericht 2019“ des Paktes für Forschung und Innovation (PFI) der Gemeinsame Wissenschaftskonferenz (GWK) betonen Bund und Länder die Notwendigkeit „durchgängige und vergleichbare Erhebungen zu Open-Access-Publikationen“ (Gemeinsame Wissenschaftskonferenz, 2019, S. 16) zu etablieren. In einem 2022 veröffentlichten Diskussionspapier der AG Wissenschaftliches Publikationssystem in der Schwerpunktinitiative „Digitale Information“ der Allianz wird ein erster Vorschlag für eine gemeinsame Indikatorik zu OA für Deutschland formuliert (Deinzer et al., 2022). Problem dieses Vorschlags ist, dass er bisher nicht über die AG hinaus diskutiert wurde.\nDas AP 4 setzt auf dieser Arbeit - an der ein Antragsteller als Leiter der zuständigen Task Group der AG Wissenschaftliches Publikationssystem beteiligt war - auf und organisiert auf Basis des Diskussionspapiers einen Dialog zur Weiterentwicklung dieses Vorschlags. Ziel ist es, einen nationalen Standard zur Definition von OA für das Reporting und eine damit verbundene Erhebungspraxis."
  },
  {
    "objectID": "aps/AP1.html#beschreibung",
    "href": "aps/AP1.html#beschreibung",
    "title": "AP 1 Institutionelle Ebene",
    "section": "Beschreibung",
    "text": "Beschreibung\nGrundlage für das Gesamtvorhaben ist eine Bestandsaufnahme, die das Thema, die Akteure und das Zusammenspiel von Aspekten der Datenanalysen zur Gestaltung der OA-Transformation eruiert und dokumentiert. Hierzu wird ein zielgruppenspezifischer Blick auf Professionals eingenommen, die sich auf Basis von Publikations- und Kostendaten mit der OA-Transformation in operativen und strategischen Bereichen wissenschaftlicher Einrichtungen befassen. Im Fokus steht dabei das Personal in Administration und Bibliothek an Hochschulen und außeruniversitären Einrichtungen. Dies sind u.a. Professionals in den Bereichen Digitales Publizieren, OA, Erwerbung und Bestandsentwicklung, Forschungsinformation sowie Forschungsförderung.\nAuf Basis einer Stakeholder-Analyse (T1.1) wird der Informationsbedarf, der Umgang mit Datenquellen sowie die Interdependenz rund um Datenanalysen im Kontext der OA-Transformation an wissenschaftlichen Einrichtungen erhoben (T1.2). Hierbei wird auch das Potenzial der sich im Aufbau befindlichen Monitoringsysteme zu Open Science betrachtet. Mit der so erzielten Bestandsaufnahme (T1.3), die die spezifischen Praktiken im Umgang mit Daten zu OA und zukünftigen Anforderungen der Agierenden betrachtet, wird die Grundlage für Empfehlungen zum Thema geschaffen (AP 5)."
  },
  {
    "objectID": "partners.html",
    "href": "partners.html",
    "title": "Projektpartner",
    "section": "",
    "text": "Die Professur Information Management am Institut für Bibliotheks- und Informationswissenschaft der HU untersucht die Rolle digitaler Forschungs- und Informationsinfrastrukturen in der Wissenschaft im Kontext der digitalen Transformation. Dabei liegt der Fokus auf Informationsinfrastrukturen, die die Sammlung, Erschließung, Zugänglichmachung und Nachnutzung von Informationsobjekten im Sinne von Open Science ermöglichen. In Forschung, Lehre und Transfer werden Prozesse der digitalen Wissenschaftskommunikation und damit verbundene Praktiken, Standards und Policies betrachtet. Ein Schwerpunkt der Forschung liegt auf dem Thema Open Access und damit verbundenen Entwicklungen der digitalen Wissenschaftskommunikation.\n\n\nHeinz Pampel https://orcid.org/0000-0003-3334-2771\nDorothea Strecker https://orcid.org/0000-0002-9754-3807"
  },
  {
    "objectID": "partners.html#humboldt-universität-zu-berlin-institut-für-bibliotheks--und-informationswissenschaft",
    "href": "partners.html#humboldt-universität-zu-berlin-institut-für-bibliotheks--und-informationswissenschaft",
    "title": "Projektpartner",
    "section": "",
    "text": "Die Professur Information Management am Institut für Bibliotheks- und Informationswissenschaft der HU untersucht die Rolle digitaler Forschungs- und Informationsinfrastrukturen in der Wissenschaft im Kontext der digitalen Transformation. Dabei liegt der Fokus auf Informationsinfrastrukturen, die die Sammlung, Erschließung, Zugänglichmachung und Nachnutzung von Informationsobjekten im Sinne von Open Science ermöglichen. In Forschung, Lehre und Transfer werden Prozesse der digitalen Wissenschaftskommunikation und damit verbundene Praktiken, Standards und Policies betrachtet. Ein Schwerpunkt der Forschung liegt auf dem Thema Open Access und damit verbundenen Entwicklungen der digitalen Wissenschaftskommunikation.\n\n\nHeinz Pampel https://orcid.org/0000-0003-3334-2771\nDorothea Strecker https://orcid.org/0000-0002-9754-3807"
  },
  {
    "objectID": "partners.html#helmholtz-open-science-office",
    "href": "partners.html#helmholtz-open-science-office",
    "title": "Projektpartner",
    "section": "Helmholtz Open Science Office",
    "text": "Helmholtz Open Science Office\nDie Helmholtz-Gemeinschaft unterstützt OA entsprechend der „Berliner Erklärung über den freien Zugang zu wissenschaftlichem Wissen“. Mit dem Helmholtz Open Science Office (OS Office) wurde eine Infrastruktur etabliert, die den Kulturwandel hin zu Open Science in Helmholtz fördert. Das OS Office versteht sich als Dienstleister und zentrenübergreifender Partner aller an diesem Prozess beteiligten Akteur:innen, der die Helmholtz-Gemeinschaft bei der Gestaltung des Kulturwandels hin zu Open Science auf nationaler und internationaler Ebene unterstützt. Mit dieser Zielsetzung engagiert sich das OS Office in einer Vielzahl von Open-Science-Initiativen und Projekten, wie z. B. in relevanten Arbeitsgruppen der Schwerpunktinitiative „Digitale Information“ der Allianz der Wissenschaftsorganisationen, im Vorstand und in diversen Gremien der DINI sowie des Vereins RDA DE und im Rahmen diverser Drittmittelprojekte.\n\nTeam\nMathijs Vleugel https://orcid.org/0000-0003-2988-2628\nLea Maria Ferguson https://orcid.org/0000-0002-7060-3670\nJohannes Schneider https://orcid.org/0009-0004-6510-166X"
  },
  {
    "objectID": "partners.html#niedersachsische-staats--und-universitatsbibliothek-gottingen",
    "href": "partners.html#niedersachsische-staats--und-universitatsbibliothek-gottingen",
    "title": "Projektpartner",
    "section": "Niedersächsische Staats- und Universitätsbibliothek Göttingen",
    "text": "Niedersächsische Staats- und Universitätsbibliothek Göttingen\nDie Niedersächsische Staats- und Universitätsbibliothek Göttingen (SUB Göttingen) gehört mit ihrem vielfältigen Aufgabenspektrum, das sie auf lokaler, regionaler, nationaler und internationaler Ebene erfüllt, zu den führenden Bibliotheken Deutschlands. Als international anerkanntes Kompetenzzentrum für die Digitale Bibliothek stellt sie der Forschung neue Services zur Verfügung. Zu ihren Aufgaben zählen u.a. die Sicherung der überregionalen Literaturversorgung wie im DFG geförderten Programm „Fachinformationsdienste für die Wissenschaft“, die Erhaltung und Zugänglichmachung von wissenschaftlichen Ergebnissen und des kulturhistorischen Erbes sowie die Selbstverpflichtung, Forschungs- und Entwicklungspartnerin für eine zukunftssichere Forschungs- und Informationsinfrastruktur in Deutschland und international zu sein.\n\nTeam\nNajko Jahn https://orcid.org/0000-0001-5105-1463\nBirgit Schmidt https://orcid.org/0000-0001-8036-5859\nSophia Dörner https://orcid.org/0000-0001-8747-3422"
  },
  {
    "objectID": "arbeitspakete.html",
    "href": "arbeitspakete.html",
    "title": "Arbeitspakete",
    "section": "",
    "text": "AP 1 Institutionelle Ebene\nZiel des AP 1 ist die Erhebung, Analyse und Dokumentation von Anforderungen an Datenanalysen rund um die OA- Transformation aus der institutionellen Praxis wissenschaftlicher Einrichtungen. Die Ergebnisse des AP 1 werden in einem Report veröffentlicht und in Empfehlungen formuliert.\n\n\nAP 2 Verlagsverträge\nZiel des AP 2 ist es, Verlagsverträge bezogen auf offene Metadaten und datenanalytische Forschungsservices zu analysieren und Best Practices zu identifizieren. Ergebnis sind eine Bestandsaufnahme bezogen auf deutsche Transformationsverträge und eine Handlungsempfehlung.\n\n\nAP 3 Open Access in institutionellen Rankings\nZiel des AP 3 ist es, OA als Bewertungsdimension von Institutionsrankings kritisch zu begleiten. Zu diesem Zweck sollen auf Grundlage einer Bestandsaufnahme von Instituionsrankings Interpretations- und Interventionshilfen für Leitungen wissenschaftlicher Einrichtungen erstellt werden. Zum anderen werden datenanalytische Hilfestellungen entwickelt und veröffentlicht, mit denen Einrichtungen und Konsortien ein Benchmarking auf Basis von Daten aus Hochschulrankings durchführen können.\n\n\nAP 4 Open-Access-Reporting\nZiel des AP 4 ist, einen Beitrag zur Verbesserung der Datenqualität zu leisten und die Standardisierung von Daten und Berichten zur OA-Transformation zu fördern. Als Ergebnis des AP 4 wird der Vorschlag eines Standards der Allianz der Wissenschaftsorganisationen zum OA-Reporting im Rahmen eines Beurteilungsprozesses weiterentwickelt.\n\n\nAP 5 Synopse\nZiel des AP 5 ist die Synopse der Ergebnisse aus den APs 1, 2, 3 und 4 in einer strategischen Empfehlung zur Datenpraxis zur Gestaltung der OA-Transformation.\n\n\nAP 6 Trainings\nZiel des AP 6 ist es, offene Trainingsmaterialien zur Verwendung offener Datenquellen und Werkzeuge in Form eines Carpentry Moduls partizipativ zu entwickeln und zu erproben. Die Arbeitsplanung orientiert sich am Lebenszyklus der Carpentries Lessons und umfasst die Ausschreibung zur Teamarbeit, Erstellung der Kursmaterialien, Erprobung und Revisionsphase.\n\n\nAP 7 Werkzeuge\nZiel des AP ist der Aufbau und Betrieb einer digitalen Werkzeugbox, die über Tools zur Erhebung, Analyse und Visualisierungen von Daten rund um die OA-Transformation informiert.\n\n\nAP 8 Netzwerke\nZiel des AP ist es, Netzwerke zu spezifischen Fragen der Datenarbeit zur OA-Transformation anzustoßen. Im Kern steht dabei der Dialog zu den Themen: Reporting, Verlagsdaten, Bibliometrie sowie Mentoring im Kontext der OA-Transformation. Das Projekt organisiert digitale Workshops für die Netzwerke und bietet eine Organisationsstruktur.\n\n\n\n\n Back to top"
  }
]